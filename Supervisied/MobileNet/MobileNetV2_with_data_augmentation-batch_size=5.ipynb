{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MobileNetV2 in Cifar10 with Augmentation Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries,Training,Testing Datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "transform_Training = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "transform_Testing = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    \n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_Training)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_Testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Test Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=5, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=5, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building The Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes, expansion, stride):\n",
    "        super(Block, self).__init__()\n",
    "        self.stride = stride\n",
    "\n",
    "        planes = expansion * in_planes\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, groups=planes, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, out_planes, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(out_planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride == 1 and in_planes != out_planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "                nn.BatchNorm2d(out_planes),\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        out = out + self.shortcut(x) if self.stride==1 else out\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MobileNetV2(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(MobileNetV2, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.layers = self._make_layers(in_planes=32)\n",
    "        self.conv2 = nn.Conv2d(320, 1280, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(1280)\n",
    "        self.linear = nn.Linear(1280, num_classes)\n",
    "\n",
    "    def _make_layers(self, in_planes):\n",
    "        cfg = [(1, 16, 1, 1),\n",
    "               (6, 24, 2, 1),  \n",
    "               (6, 32, 3, 2),\n",
    "               (6, 64, 4, 2),\n",
    "               (6, 96, 3, 1),\n",
    "               (6, 160, 3, 2),\n",
    "               (6, 320, 1, 1)]\n",
    "        layers = []\n",
    "        for expansion, out_planes, num_blocks, stride in cfg:\n",
    "            strides = [stride] + [1]*(num_blocks-1)\n",
    "            for stride in strides:\n",
    "                layers.append(Block(in_planes, out_planes, expansion, stride))\n",
    "                in_planes = out_planes\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layers(out)\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 10])\n"
     ]
    }
   ],
   "source": [
    "def test():\n",
    "    net = MobileNetV2()\n",
    "    x = torch.randn(2, 3, 32, 32)  \n",
    "    y = net(x)\n",
    "    print(y.size()) \n",
    "\n",
    "test()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = MobileNetV2(num_classes=10)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   200] loss: 2.329\n",
      "[1,   400] loss: 2.194\n",
      "[1,   600] loss: 2.148\n",
      "[1,   800] loss: 2.104\n",
      "[1,  1000] loss: 2.066\n",
      "[1,  1200] loss: 2.044\n",
      "[1,  1400] loss: 2.003\n",
      "[1,  1600] loss: 1.969\n",
      "[1,  1800] loss: 1.969\n",
      "[1,  2000] loss: 1.938\n",
      "[1,  2200] loss: 1.940\n",
      "[1,  2400] loss: 1.909\n",
      "[1,  2600] loss: 1.981\n",
      "[1,  2800] loss: 1.920\n",
      "[1,  3000] loss: 1.890\n",
      "[1,  3200] loss: 1.837\n",
      "[1,  3400] loss: 1.843\n",
      "[1,  3600] loss: 1.869\n",
      "[1,  3800] loss: 1.782\n",
      "[1,  4000] loss: 1.778\n",
      "[1,  4200] loss: 1.788\n",
      "[1,  4400] loss: 1.816\n",
      "[1,  4600] loss: 1.696\n",
      "[1,  4800] loss: 1.731\n",
      "[1,  5000] loss: 1.802\n",
      "[1,  5200] loss: 1.736\n",
      "[1,  5400] loss: 1.706\n",
      "[1,  5600] loss: 1.721\n",
      "[1,  5800] loss: 1.671\n",
      "[1,  6000] loss: 1.677\n",
      "[1,  6200] loss: 1.664\n",
      "[1,  6400] loss: 1.687\n",
      "[1,  6600] loss: 1.599\n",
      "[1,  6800] loss: 1.639\n",
      "[1,  7000] loss: 1.638\n",
      "[1,  7200] loss: 1.627\n",
      "[1,  7400] loss: 1.630\n",
      "[1,  7600] loss: 1.545\n",
      "[1,  7800] loss: 1.538\n",
      "[1,  8000] loss: 1.583\n",
      "[1,  8200] loss: 1.586\n",
      "[1,  8400] loss: 1.536\n",
      "[1,  8600] loss: 1.533\n",
      "[1,  8800] loss: 1.526\n",
      "[1,  9000] loss: 1.516\n",
      "[1,  9200] loss: 1.478\n",
      "[1,  9400] loss: 1.506\n",
      "[1,  9600] loss: 1.508\n",
      "[1,  9800] loss: 1.559\n",
      "[1, 10000] loss: 1.438\n",
      "[2,   200] loss: 1.462\n",
      "[2,   400] loss: 1.460\n",
      "[2,   600] loss: 1.455\n",
      "[2,   800] loss: 1.403\n",
      "[2,  1000] loss: 1.453\n",
      "[2,  1200] loss: 1.418\n",
      "[2,  1400] loss: 1.417\n",
      "[2,  1600] loss: 1.452\n",
      "[2,  1800] loss: 1.372\n",
      "[2,  2000] loss: 1.439\n",
      "[2,  2200] loss: 1.446\n",
      "[2,  2400] loss: 1.468\n",
      "[2,  2600] loss: 1.351\n",
      "[2,  2800] loss: 1.332\n",
      "[2,  3000] loss: 1.349\n",
      "[2,  3200] loss: 1.401\n",
      "[2,  3400] loss: 1.298\n",
      "[2,  3600] loss: 1.387\n",
      "[2,  3800] loss: 1.363\n",
      "[2,  4000] loss: 1.327\n",
      "[2,  4200] loss: 1.340\n",
      "[2,  4400] loss: 1.293\n",
      "[2,  4600] loss: 1.323\n",
      "[2,  4800] loss: 1.273\n",
      "[2,  5000] loss: 1.288\n",
      "[2,  5200] loss: 1.315\n",
      "[2,  5400] loss: 1.394\n",
      "[2,  5600] loss: 1.251\n",
      "[2,  5800] loss: 1.256\n",
      "[2,  6000] loss: 1.306\n",
      "[2,  6200] loss: 1.300\n",
      "[2,  6400] loss: 1.205\n",
      "[2,  6600] loss: 1.270\n",
      "[2,  6800] loss: 1.226\n",
      "[2,  7000] loss: 1.290\n",
      "[2,  7200] loss: 1.260\n",
      "[2,  7400] loss: 1.244\n",
      "[2,  7600] loss: 1.242\n",
      "[2,  7800] loss: 1.266\n",
      "[2,  8000] loss: 1.194\n",
      "[2,  8200] loss: 1.177\n",
      "[2,  8400] loss: 1.227\n",
      "[2,  8600] loss: 1.272\n",
      "[2,  8800] loss: 1.250\n",
      "[2,  9000] loss: 1.187\n",
      "[2,  9200] loss: 1.237\n",
      "[2,  9400] loss: 1.178\n",
      "[2,  9600] loss: 1.191\n",
      "[2,  9800] loss: 1.181\n",
      "[2, 10000] loss: 1.190\n",
      "[3,   200] loss: 1.195\n",
      "[3,   400] loss: 1.144\n",
      "[3,   600] loss: 1.233\n",
      "[3,   800] loss: 1.216\n",
      "[3,  1000] loss: 1.173\n",
      "[3,  1200] loss: 1.164\n",
      "[3,  1400] loss: 1.197\n",
      "[3,  1600] loss: 1.143\n",
      "[3,  1800] loss: 1.194\n",
      "[3,  2000] loss: 1.099\n",
      "[3,  2200] loss: 1.118\n",
      "[3,  2400] loss: 1.064\n",
      "[3,  2600] loss: 1.131\n",
      "[3,  2800] loss: 1.151\n",
      "[3,  3000] loss: 1.080\n",
      "[3,  3200] loss: 1.085\n",
      "[3,  3400] loss: 1.102\n",
      "[3,  3600] loss: 1.108\n",
      "[3,  3800] loss: 1.139\n",
      "[3,  4000] loss: 1.010\n",
      "[3,  4200] loss: 1.148\n",
      "[3,  4400] loss: 1.062\n",
      "[3,  4600] loss: 1.063\n",
      "[3,  4800] loss: 1.123\n",
      "[3,  5000] loss: 1.058\n",
      "[3,  5200] loss: 1.075\n",
      "[3,  5400] loss: 1.063\n",
      "[3,  5600] loss: 1.073\n",
      "[3,  5800] loss: 1.019\n",
      "[3,  6000] loss: 1.062\n",
      "[3,  6200] loss: 1.038\n",
      "[3,  6400] loss: 1.075\n",
      "[3,  6600] loss: 1.078\n",
      "[3,  6800] loss: 1.112\n",
      "[3,  7000] loss: 1.005\n",
      "[3,  7200] loss: 1.066\n",
      "[3,  7400] loss: 1.009\n",
      "[3,  7600] loss: 0.992\n",
      "[3,  7800] loss: 0.979\n",
      "[3,  8000] loss: 1.046\n",
      "[3,  8200] loss: 0.968\n",
      "[3,  8400] loss: 1.023\n",
      "[3,  8600] loss: 1.080\n",
      "[3,  8800] loss: 1.044\n",
      "[3,  9000] loss: 0.990\n",
      "[3,  9200] loss: 1.024\n",
      "[3,  9400] loss: 1.035\n",
      "[3,  9600] loss: 1.002\n",
      "[3,  9800] loss: 0.984\n",
      "[3, 10000] loss: 0.940\n",
      "[4,   200] loss: 0.915\n",
      "[4,   400] loss: 1.013\n",
      "[4,   600] loss: 0.914\n",
      "[4,   800] loss: 0.991\n",
      "[4,  1000] loss: 0.991\n",
      "[4,  1200] loss: 0.972\n",
      "[4,  1400] loss: 0.976\n",
      "[4,  1600] loss: 0.931\n",
      "[4,  1800] loss: 1.000\n",
      "[4,  2000] loss: 0.957\n",
      "[4,  2200] loss: 0.965\n",
      "[4,  2400] loss: 0.966\n",
      "[4,  2600] loss: 0.943\n",
      "[4,  2800] loss: 0.936\n",
      "[4,  3000] loss: 1.018\n",
      "[4,  3200] loss: 0.934\n",
      "[4,  3400] loss: 1.007\n",
      "[4,  3600] loss: 0.971\n",
      "[4,  3800] loss: 0.981\n",
      "[4,  4000] loss: 0.960\n",
      "[4,  4200] loss: 0.907\n",
      "[4,  4400] loss: 0.958\n",
      "[4,  4600] loss: 0.928\n",
      "[4,  4800] loss: 0.881\n",
      "[4,  5000] loss: 0.943\n",
      "[4,  5200] loss: 0.923\n",
      "[4,  5400] loss: 0.938\n",
      "[4,  5600] loss: 0.948\n",
      "[4,  5800] loss: 0.909\n",
      "[4,  6000] loss: 0.972\n",
      "[4,  6200] loss: 0.897\n",
      "[4,  6400] loss: 0.919\n",
      "[4,  6600] loss: 0.958\n",
      "[4,  6800] loss: 0.924\n",
      "[4,  7000] loss: 0.916\n",
      "[4,  7200] loss: 0.918\n",
      "[4,  7400] loss: 0.871\n",
      "[4,  7600] loss: 0.931\n",
      "[4,  7800] loss: 0.855\n",
      "[4,  8000] loss: 0.868\n",
      "[4,  8200] loss: 0.904\n",
      "[4,  8400] loss: 0.875\n",
      "[4,  8600] loss: 0.892\n",
      "[4,  8800] loss: 0.912\n",
      "[4,  9000] loss: 0.858\n",
      "[4,  9200] loss: 0.801\n",
      "[4,  9400] loss: 0.855\n",
      "[4,  9600] loss: 0.905\n",
      "[4,  9800] loss: 0.930\n",
      "[4, 10000] loss: 0.867\n",
      "[5,   200] loss: 0.888\n",
      "[5,   400] loss: 0.881\n",
      "[5,   600] loss: 0.812\n",
      "[5,   800] loss: 0.843\n",
      "[5,  1000] loss: 0.834\n",
      "[5,  1200] loss: 0.828\n",
      "[5,  1400] loss: 0.819\n",
      "[5,  1600] loss: 0.891\n",
      "[5,  1800] loss: 0.897\n",
      "[5,  2000] loss: 0.891\n",
      "[5,  2200] loss: 0.808\n",
      "[5,  2400] loss: 0.883\n",
      "[5,  2600] loss: 0.820\n",
      "[5,  2800] loss: 0.852\n",
      "[5,  3000] loss: 0.817\n",
      "[5,  3200] loss: 0.831\n",
      "[5,  3400] loss: 0.793\n",
      "[5,  3600] loss: 0.881\n",
      "[5,  3800] loss: 0.885\n",
      "[5,  4000] loss: 0.827\n",
      "[5,  4200] loss: 0.797\n",
      "[5,  4400] loss: 0.809\n",
      "[5,  4600] loss: 0.824\n",
      "[5,  4800] loss: 0.869\n",
      "[5,  5000] loss: 0.797\n",
      "[5,  5200] loss: 0.879\n",
      "[5,  5400] loss: 0.885\n",
      "[5,  5600] loss: 0.809\n",
      "[5,  5800] loss: 0.824\n",
      "[5,  6000] loss: 0.796\n",
      "[5,  6200] loss: 0.840\n",
      "[5,  6400] loss: 0.777\n",
      "[5,  6600] loss: 0.784\n",
      "[5,  6800] loss: 0.857\n",
      "[5,  7000] loss: 0.870\n",
      "[5,  7200] loss: 0.863\n",
      "[5,  7400] loss: 0.752\n",
      "[5,  7600] loss: 0.809\n",
      "[5,  7800] loss: 0.756\n",
      "[5,  8000] loss: 0.821\n",
      "[5,  8200] loss: 0.838\n",
      "[5,  8400] loss: 0.821\n",
      "[5,  8600] loss: 0.780\n",
      "[5,  8800] loss: 0.854\n",
      "[5,  9000] loss: 0.803\n",
      "[5,  9200] loss: 0.807\n",
      "[5,  9400] loss: 0.821\n",
      "[5,  9600] loss: 0.804\n",
      "[5,  9800] loss: 0.875\n",
      "[5, 10000] loss: 0.807\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "for epoch in range(5):  \n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 200 == 199:    \n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 200))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 70 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6,   200] loss: 0.760\n",
      "[6,   400] loss: 0.693\n",
      "[6,   600] loss: 0.804\n",
      "[6,   800] loss: 0.799\n",
      "[6,  1000] loss: 0.747\n",
      "[6,  1200] loss: 0.783\n",
      "[6,  1400] loss: 0.841\n",
      "[6,  1600] loss: 0.751\n",
      "[6,  1800] loss: 0.809\n",
      "[6,  2000] loss: 0.768\n",
      "[6,  2200] loss: 0.823\n",
      "[6,  2400] loss: 0.758\n",
      "[6,  2600] loss: 0.768\n",
      "[6,  2800] loss: 0.739\n",
      "[6,  3000] loss: 0.696\n",
      "[6,  3200] loss: 0.802\n",
      "[6,  3400] loss: 0.787\n",
      "[6,  3600] loss: 0.788\n",
      "[6,  3800] loss: 0.714\n",
      "[6,  4000] loss: 0.746\n",
      "[6,  4200] loss: 0.817\n",
      "[6,  4400] loss: 0.751\n",
      "[6,  4600] loss: 0.771\n",
      "[6,  4800] loss: 0.776\n",
      "[6,  5000] loss: 0.751\n",
      "[6,  5200] loss: 0.722\n",
      "[6,  5400] loss: 0.829\n",
      "[6,  5600] loss: 0.715\n",
      "[6,  5800] loss: 0.811\n",
      "[6,  6000] loss: 0.769\n",
      "[6,  6200] loss: 0.770\n",
      "[6,  6400] loss: 0.781\n",
      "[6,  6600] loss: 0.744\n",
      "[6,  6800] loss: 0.712\n",
      "[6,  7000] loss: 0.671\n",
      "[6,  7200] loss: 0.691\n",
      "[6,  7400] loss: 0.785\n",
      "[6,  7600] loss: 0.786\n",
      "[6,  7800] loss: 0.816\n",
      "[6,  8000] loss: 0.709\n",
      "[6,  8200] loss: 0.687\n",
      "[6,  8400] loss: 0.722\n",
      "[6,  8600] loss: 0.795\n",
      "[6,  8800] loss: 0.699\n",
      "[6,  9000] loss: 0.711\n",
      "[6,  9200] loss: 0.681\n",
      "[6,  9400] loss: 0.648\n",
      "[6,  9600] loss: 0.774\n",
      "[6,  9800] loss: 0.730\n",
      "[6, 10000] loss: 0.773\n",
      "[7,   200] loss: 0.686\n",
      "[7,   400] loss: 0.727\n",
      "[7,   600] loss: 0.738\n",
      "[7,   800] loss: 0.684\n",
      "[7,  1000] loss: 0.645\n",
      "[7,  1200] loss: 0.740\n",
      "[7,  1400] loss: 0.700\n",
      "[7,  1600] loss: 0.758\n",
      "[7,  1800] loss: 0.702\n",
      "[7,  2000] loss: 0.678\n",
      "[7,  2200] loss: 0.701\n",
      "[7,  2400] loss: 0.684\n",
      "[7,  2600] loss: 0.747\n",
      "[7,  2800] loss: 0.629\n",
      "[7,  3000] loss: 0.733\n",
      "[7,  3200] loss: 0.696\n",
      "[7,  3400] loss: 0.646\n",
      "[7,  3600] loss: 0.659\n",
      "[7,  3800] loss: 0.724\n",
      "[7,  4000] loss: 0.662\n",
      "[7,  4200] loss: 0.661\n",
      "[7,  4400] loss: 0.735\n",
      "[7,  4600] loss: 0.714\n",
      "[7,  4800] loss: 0.725\n",
      "[7,  5000] loss: 0.656\n",
      "[7,  5200] loss: 0.631\n",
      "[7,  5400] loss: 0.653\n",
      "[7,  5600] loss: 0.678\n",
      "[7,  5800] loss: 0.723\n",
      "[7,  6000] loss: 0.689\n",
      "[7,  6200] loss: 0.727\n",
      "[7,  6400] loss: 0.701\n",
      "[7,  6600] loss: 0.687\n",
      "[7,  6800] loss: 0.684\n",
      "[7,  7000] loss: 0.674\n",
      "[7,  7200] loss: 0.715\n",
      "[7,  7400] loss: 0.706\n",
      "[7,  7600] loss: 0.700\n",
      "[7,  7800] loss: 0.762\n",
      "[7,  8000] loss: 0.699\n",
      "[7,  8200] loss: 0.663\n",
      "[7,  8400] loss: 0.669\n",
      "[7,  8600] loss: 0.617\n",
      "[7,  8800] loss: 0.581\n",
      "[7,  9000] loss: 0.673\n",
      "[7,  9200] loss: 0.669\n",
      "[7,  9400] loss: 0.658\n",
      "[7,  9600] loss: 0.723\n",
      "[7,  9800] loss: 0.728\n",
      "[7, 10000] loss: 0.703\n",
      "[8,   200] loss: 0.691\n",
      "[8,   400] loss: 0.636\n",
      "[8,   600] loss: 0.657\n",
      "[8,   800] loss: 0.653\n",
      "[8,  1000] loss: 0.642\n",
      "[8,  1200] loss: 0.631\n",
      "[8,  1400] loss: 0.652\n",
      "[8,  1600] loss: 0.665\n",
      "[8,  1800] loss: 0.645\n",
      "[8,  2000] loss: 0.649\n",
      "[8,  2200] loss: 0.691\n",
      "[8,  2400] loss: 0.636\n",
      "[8,  2600] loss: 0.645\n",
      "[8,  2800] loss: 0.621\n",
      "[8,  3000] loss: 0.688\n",
      "[8,  3200] loss: 0.560\n",
      "[8,  3400] loss: 0.697\n",
      "[8,  3600] loss: 0.631\n",
      "[8,  3800] loss: 0.649\n",
      "[8,  4000] loss: 0.661\n",
      "[8,  4200] loss: 0.663\n",
      "[8,  4400] loss: 0.649\n",
      "[8,  4600] loss: 0.660\n",
      "[8,  4800] loss: 0.667\n",
      "[8,  5000] loss: 0.620\n",
      "[8,  5200] loss: 0.637\n",
      "[8,  5400] loss: 0.634\n",
      "[8,  5600] loss: 0.637\n",
      "[8,  5800] loss: 0.622\n",
      "[8,  6000] loss: 0.598\n",
      "[8,  6200] loss: 0.650\n",
      "[8,  6400] loss: 0.665\n",
      "[8,  6600] loss: 0.705\n",
      "[8,  6800] loss: 0.620\n",
      "[8,  7000] loss: 0.658\n",
      "[8,  7200] loss: 0.635\n",
      "[8,  7400] loss: 0.597\n",
      "[8,  7600] loss: 0.627\n",
      "[8,  7800] loss: 0.666\n",
      "[8,  8000] loss: 0.640\n",
      "[8,  8200] loss: 0.635\n",
      "[8,  8400] loss: 0.631\n",
      "[8,  8600] loss: 0.631\n",
      "[8,  8800] loss: 0.581\n",
      "[8,  9000] loss: 0.636\n",
      "[8,  9200] loss: 0.635\n",
      "[8,  9400] loss: 0.685\n",
      "[8,  9600] loss: 0.715\n",
      "[8,  9800] loss: 0.630\n",
      "[8, 10000] loss: 0.603\n",
      "[9,   200] loss: 0.580\n",
      "[9,   400] loss: 0.601\n",
      "[9,   600] loss: 0.586\n",
      "[9,   800] loss: 0.597\n",
      "[9,  1000] loss: 0.560\n",
      "[9,  1200] loss: 0.652\n",
      "[9,  1400] loss: 0.627\n",
      "[9,  1600] loss: 0.594\n",
      "[9,  1800] loss: 0.575\n",
      "[9,  2000] loss: 0.600\n",
      "[9,  2200] loss: 0.594\n",
      "[9,  2400] loss: 0.588\n",
      "[9,  2600] loss: 0.621\n",
      "[9,  2800] loss: 0.637\n",
      "[9,  3000] loss: 0.620\n",
      "[9,  3200] loss: 0.613\n",
      "[9,  3400] loss: 0.597\n",
      "[9,  3600] loss: 0.614\n",
      "[9,  3800] loss: 0.569\n",
      "[9,  4000] loss: 0.624\n",
      "[9,  4200] loss: 0.607\n",
      "[9,  4400] loss: 0.620\n",
      "[9,  4600] loss: 0.624\n",
      "[9,  4800] loss: 0.559\n",
      "[9,  5000] loss: 0.617\n",
      "[9,  5200] loss: 0.571\n",
      "[9,  5400] loss: 0.560\n",
      "[9,  5600] loss: 0.597\n",
      "[9,  5800] loss: 0.594\n",
      "[9,  6000] loss: 0.571\n",
      "[9,  6200] loss: 0.694\n",
      "[9,  6400] loss: 0.587\n",
      "[9,  6600] loss: 0.631\n",
      "[9,  6800] loss: 0.624\n",
      "[9,  7000] loss: 0.634\n",
      "[9,  7200] loss: 0.569\n",
      "[9,  7400] loss: 0.592\n",
      "[9,  7600] loss: 0.558\n",
      "[9,  7800] loss: 0.591\n",
      "[9,  8000] loss: 0.585\n",
      "[9,  8200] loss: 0.585\n",
      "[9,  8400] loss: 0.623\n",
      "[9,  8600] loss: 0.636\n",
      "[9,  8800] loss: 0.560\n",
      "[9,  9000] loss: 0.610\n",
      "[9,  9200] loss: 0.604\n",
      "[9,  9400] loss: 0.602\n",
      "[9,  9600] loss: 0.631\n",
      "[9,  9800] loss: 0.574\n",
      "[9, 10000] loss: 0.648\n",
      "[10,   200] loss: 0.522\n",
      "[10,   400] loss: 0.607\n",
      "[10,   600] loss: 0.507\n",
      "[10,   800] loss: 0.588\n",
      "[10,  1000] loss: 0.553\n",
      "[10,  1200] loss: 0.502\n",
      "[10,  1400] loss: 0.585\n",
      "[10,  1600] loss: 0.641\n",
      "[10,  1800] loss: 0.555\n",
      "[10,  2000] loss: 0.507\n",
      "[10,  2200] loss: 0.592\n",
      "[10,  2400] loss: 0.688\n",
      "[10,  2600] loss: 0.566\n",
      "[10,  2800] loss: 0.551\n",
      "[10,  3000] loss: 0.591\n",
      "[10,  3200] loss: 0.611\n",
      "[10,  3400] loss: 0.601\n",
      "[10,  3600] loss: 0.529\n",
      "[10,  3800] loss: 0.589\n",
      "[10,  4000] loss: 0.549\n",
      "[10,  4200] loss: 0.522\n",
      "[10,  4400] loss: 0.580\n",
      "[10,  4600] loss: 0.557\n",
      "[10,  4800] loss: 0.546\n",
      "[10,  5000] loss: 0.519\n",
      "[10,  5200] loss: 0.532\n",
      "[10,  5400] loss: 0.606\n",
      "[10,  5600] loss: 0.562\n",
      "[10,  5800] loss: 0.561\n",
      "[10,  6000] loss: 0.570\n",
      "[10,  6200] loss: 0.616\n",
      "[10,  6400] loss: 0.553\n",
      "[10,  6600] loss: 0.586\n",
      "[10,  6800] loss: 0.557\n",
      "[10,  7000] loss: 0.593\n",
      "[10,  7200] loss: 0.593\n",
      "[10,  7400] loss: 0.556\n",
      "[10,  7600] loss: 0.643\n",
      "[10,  7800] loss: 0.590\n",
      "[10,  8000] loss: 0.518\n",
      "[10,  8200] loss: 0.599\n",
      "[10,  8400] loss: 0.567\n",
      "[10,  8600] loss: 0.592\n",
      "[10,  8800] loss: 0.635\n",
      "[10,  9000] loss: 0.573\n",
      "[10,  9200] loss: 0.686\n",
      "[10,  9400] loss: 0.548\n",
      "[10,  9600] loss: 0.568\n",
      "[10,  9800] loss: 0.539\n",
      "[10, 10000] loss: 0.607\n",
      "Finished Additional Training\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "additional_epochs = 5  # Number of additional epochs to train\n",
    "\n",
    "for epoch in range(5, 5 + additional_epochs):  # Continue from epoch 10 to 30\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 200 == 199:\n",
    "            print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 200))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Additional Training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 77 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6,   200] loss: 0.559\n",
      "[6,   400] loss: 0.563\n",
      "[6,   600] loss: 0.618\n",
      "[6,   800] loss: 0.593\n",
      "[6,  1000] loss: 0.553\n",
      "[6,  1200] loss: 0.544\n",
      "[6,  1400] loss: 0.559\n",
      "[6,  1600] loss: 0.555\n",
      "[6,  1800] loss: 0.541\n",
      "[6,  2000] loss: 0.527\n",
      "[6,  2200] loss: 0.549\n",
      "[6,  2400] loss: 0.516\n",
      "[6,  2600] loss: 0.554\n",
      "[6,  2800] loss: 0.512\n",
      "[6,  3000] loss: 0.538\n",
      "[6,  3200] loss: 0.522\n",
      "[6,  3400] loss: 0.559\n",
      "[6,  3600] loss: 0.541\n",
      "[6,  3800] loss: 0.536\n",
      "[6,  4000] loss: 0.552\n",
      "[6,  4200] loss: 0.601\n",
      "[6,  4400] loss: 0.529\n",
      "[6,  4600] loss: 0.548\n",
      "[6,  4800] loss: 0.544\n",
      "[6,  5000] loss: 0.562\n",
      "[6,  5200] loss: 0.535\n",
      "[6,  5400] loss: 0.529\n",
      "[6,  5600] loss: 0.548\n",
      "[6,  5800] loss: 0.504\n",
      "[6,  6000] loss: 0.584\n",
      "[6,  6200] loss: 0.576\n",
      "[6,  6400] loss: 0.547\n",
      "[6,  6600] loss: 0.545\n",
      "[6,  6800] loss: 0.498\n",
      "[6,  7000] loss: 0.485\n",
      "[6,  7200] loss: 0.513\n",
      "[6,  7400] loss: 0.574\n",
      "[6,  7600] loss: 0.522\n",
      "[6,  7800] loss: 0.522\n",
      "[6,  8000] loss: 0.557\n",
      "[6,  8200] loss: 0.562\n",
      "[6,  8400] loss: 0.557\n",
      "[6,  8600] loss: 0.560\n",
      "[6,  8800] loss: 0.520\n",
      "[6,  9000] loss: 0.572\n",
      "[6,  9200] loss: 0.545\n",
      "[6,  9400] loss: 0.537\n",
      "[6,  9600] loss: 0.519\n",
      "[6,  9800] loss: 0.493\n",
      "[6, 10000] loss: 0.498\n",
      "[7,   200] loss: 0.561\n",
      "[7,   400] loss: 0.501\n",
      "[7,   600] loss: 0.534\n",
      "[7,   800] loss: 0.577\n",
      "[7,  1000] loss: 0.451\n",
      "[7,  1200] loss: 0.500\n",
      "[7,  1400] loss: 0.460\n",
      "[7,  1600] loss: 0.558\n",
      "[7,  1800] loss: 0.521\n",
      "[7,  2000] loss: 0.465\n",
      "[7,  2200] loss: 0.456\n",
      "[7,  2400] loss: 0.520\n",
      "[7,  2600] loss: 0.561\n",
      "[7,  2800] loss: 0.515\n",
      "[7,  3000] loss: 0.514\n",
      "[7,  3200] loss: 0.565\n",
      "[7,  3400] loss: 0.536\n",
      "[7,  3600] loss: 0.542\n",
      "[7,  3800] loss: 0.490\n",
      "[7,  4000] loss: 0.569\n",
      "[7,  4200] loss: 0.584\n",
      "[7,  4400] loss: 0.534\n",
      "[7,  4600] loss: 0.521\n",
      "[7,  4800] loss: 0.466\n",
      "[7,  5000] loss: 0.489\n",
      "[7,  5200] loss: 0.521\n",
      "[7,  5400] loss: 0.532\n",
      "[7,  5600] loss: 0.513\n",
      "[7,  5800] loss: 0.433\n",
      "[7,  6000] loss: 0.493\n",
      "[7,  6200] loss: 0.535\n",
      "[7,  6400] loss: 0.494\n",
      "[7,  6600] loss: 0.547\n",
      "[7,  6800] loss: 0.425\n",
      "[7,  7000] loss: 0.574\n",
      "[7,  7200] loss: 0.538\n",
      "[7,  7400] loss: 0.500\n",
      "[7,  7600] loss: 0.524\n",
      "[7,  7800] loss: 0.568\n",
      "[7,  8000] loss: 0.552\n",
      "[7,  8200] loss: 0.508\n",
      "[7,  8400] loss: 0.509\n",
      "[7,  8600] loss: 0.513\n",
      "[7,  8800] loss: 0.513\n",
      "[7,  9000] loss: 0.556\n",
      "[7,  9200] loss: 0.477\n",
      "[7,  9400] loss: 0.496\n",
      "[7,  9600] loss: 0.522\n",
      "[7,  9800] loss: 0.583\n",
      "[7, 10000] loss: 0.528\n",
      "[8,   200] loss: 0.503\n",
      "[8,   400] loss: 0.467\n",
      "[8,   600] loss: 0.464\n",
      "[8,   800] loss: 0.432\n",
      "[8,  1000] loss: 0.500\n",
      "[8,  1200] loss: 0.567\n",
      "[8,  1400] loss: 0.469\n",
      "[8,  1600] loss: 0.538\n",
      "[8,  1800] loss: 0.459\n",
      "[8,  2000] loss: 0.499\n",
      "[8,  2200] loss: 0.497\n",
      "[8,  2400] loss: 0.519\n",
      "[8,  2600] loss: 0.469\n",
      "[8,  2800] loss: 0.503\n",
      "[8,  3000] loss: 0.460\n",
      "[8,  3200] loss: 0.539\n",
      "[8,  3400] loss: 0.502\n",
      "[8,  3600] loss: 0.451\n",
      "[8,  3800] loss: 0.519\n",
      "[8,  4000] loss: 0.520\n",
      "[8,  4200] loss: 0.451\n",
      "[8,  4400] loss: 0.548\n",
      "[8,  4600] loss: 0.510\n",
      "[8,  4800] loss: 0.529\n",
      "[8,  5000] loss: 0.504\n",
      "[8,  5200] loss: 0.548\n",
      "[8,  5400] loss: 0.448\n",
      "[8,  5600] loss: 0.505\n",
      "[8,  5800] loss: 0.474\n",
      "[8,  6000] loss: 0.497\n",
      "[8,  6200] loss: 0.526\n",
      "[8,  6400] loss: 0.463\n",
      "[8,  6600] loss: 0.546\n",
      "[8,  6800] loss: 0.505\n",
      "[8,  7000] loss: 0.457\n",
      "[8,  7200] loss: 0.489\n",
      "[8,  7400] loss: 0.534\n",
      "[8,  7600] loss: 0.533\n",
      "[8,  7800] loss: 0.452\n",
      "[8,  8000] loss: 0.490\n",
      "[8,  8200] loss: 0.473\n",
      "[8,  8400] loss: 0.452\n",
      "[8,  8600] loss: 0.555\n",
      "[8,  8800] loss: 0.526\n",
      "[8,  9000] loss: 0.483\n",
      "[8,  9200] loss: 0.494\n",
      "[8,  9400] loss: 0.518\n",
      "[8,  9600] loss: 0.432\n",
      "[8,  9800] loss: 0.502\n",
      "[8, 10000] loss: 0.522\n",
      "[9,   200] loss: 0.461\n",
      "[9,   400] loss: 0.446\n",
      "[9,   600] loss: 0.523\n",
      "[9,   800] loss: 0.503\n",
      "[9,  1000] loss: 0.507\n",
      "[9,  1200] loss: 0.473\n",
      "[9,  1400] loss: 0.415\n",
      "[9,  1600] loss: 0.512\n",
      "[9,  1800] loss: 0.445\n",
      "[9,  2000] loss: 0.439\n",
      "[9,  2200] loss: 0.509\n",
      "[9,  2400] loss: 0.464\n",
      "[9,  2600] loss: 0.445\n",
      "[9,  2800] loss: 0.446\n",
      "[9,  3000] loss: 0.443\n",
      "[9,  3200] loss: 0.487\n",
      "[9,  3400] loss: 0.504\n",
      "[9,  3600] loss: 0.491\n",
      "[9,  3800] loss: 0.467\n",
      "[9,  4000] loss: 0.520\n",
      "[9,  4200] loss: 0.476\n",
      "[9,  4400] loss: 0.450\n",
      "[9,  4600] loss: 0.446\n",
      "[9,  4800] loss: 0.494\n",
      "[9,  5000] loss: 0.550\n",
      "[9,  5200] loss: 0.452\n",
      "[9,  5400] loss: 0.439\n",
      "[9,  5600] loss: 0.491\n",
      "[9,  5800] loss: 0.503\n",
      "[9,  6000] loss: 0.490\n",
      "[9,  6200] loss: 0.489\n",
      "[9,  6400] loss: 0.436\n",
      "[9,  6600] loss: 0.465\n",
      "[9,  6800] loss: 0.436\n",
      "[9,  7000] loss: 0.445\n",
      "[9,  7200] loss: 0.495\n",
      "[9,  7400] loss: 0.497\n",
      "[9,  7600] loss: 0.476\n",
      "[9,  7800] loss: 0.486\n",
      "[9,  8000] loss: 0.430\n",
      "[9,  8200] loss: 0.480\n",
      "[9,  8400] loss: 0.402\n",
      "[9,  8600] loss: 0.472\n",
      "[9,  8800] loss: 0.465\n",
      "[9,  9000] loss: 0.442\n",
      "[9,  9200] loss: 0.433\n",
      "[9,  9400] loss: 0.461\n",
      "[9,  9600] loss: 0.449\n",
      "[9,  9800] loss: 0.396\n",
      "[9, 10000] loss: 0.467\n",
      "[10,   200] loss: 0.443\n",
      "[10,   400] loss: 0.418\n",
      "[10,   600] loss: 0.405\n",
      "[10,   800] loss: 0.409\n",
      "[10,  1000] loss: 0.444\n",
      "[10,  1200] loss: 0.451\n",
      "[10,  1400] loss: 0.418\n",
      "[10,  1600] loss: 0.401\n",
      "[10,  1800] loss: 0.454\n",
      "[10,  2000] loss: 0.479\n",
      "[10,  2200] loss: 0.480\n",
      "[10,  2400] loss: 0.467\n",
      "[10,  2600] loss: 0.469\n",
      "[10,  2800] loss: 0.421\n",
      "[10,  3000] loss: 0.389\n",
      "[10,  3200] loss: 0.472\n",
      "[10,  3400] loss: 0.451\n",
      "[10,  3600] loss: 0.493\n",
      "[10,  3800] loss: 0.475\n",
      "[10,  4000] loss: 0.407\n",
      "[10,  4200] loss: 0.461\n",
      "[10,  4400] loss: 0.458\n",
      "[10,  4600] loss: 0.454\n",
      "[10,  4800] loss: 0.490\n",
      "[10,  5000] loss: 0.396\n",
      "[10,  5200] loss: 0.485\n",
      "[10,  5400] loss: 0.446\n",
      "[10,  5600] loss: 0.429\n",
      "[10,  5800] loss: 0.430\n",
      "[10,  6000] loss: 0.511\n",
      "[10,  6200] loss: 0.483\n",
      "[10,  6400] loss: 0.434\n",
      "[10,  6600] loss: 0.381\n",
      "[10,  6800] loss: 0.468\n",
      "[10,  7000] loss: 0.437\n",
      "[10,  7200] loss: 0.517\n",
      "[10,  7400] loss: 0.427\n",
      "[10,  7600] loss: 0.537\n",
      "[10,  7800] loss: 0.402\n",
      "[10,  8000] loss: 0.456\n",
      "[10,  8200] loss: 0.485\n",
      "[10,  8400] loss: 0.443\n",
      "[10,  8600] loss: 0.473\n",
      "[10,  8800] loss: 0.520\n",
      "[10,  9000] loss: 0.492\n",
      "[10,  9200] loss: 0.426\n",
      "[10,  9400] loss: 0.421\n",
      "[10,  9600] loss: 0.481\n",
      "[10,  9800] loss: 0.463\n",
      "[10, 10000] loss: 0.472\n",
      "Finished Additional Training\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "additional_epochs = 5  # Number of additional epochs to train\n",
    "\n",
    "for epoch in range(5, 5 + additional_epochs):  # Continue from epoch 10 to 30\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 200 == 199:\n",
    "            print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 200))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Additional Training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 79 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6,   200] loss: 0.436\n",
      "[6,   400] loss: 0.421\n",
      "[6,   600] loss: 0.483\n",
      "[6,   800] loss: 0.380\n",
      "[6,  1000] loss: 0.483\n",
      "[6,  1200] loss: 0.489\n",
      "[6,  1400] loss: 0.436\n",
      "[6,  1600] loss: 0.441\n",
      "[6,  1800] loss: 0.449\n",
      "[6,  2000] loss: 0.389\n",
      "[6,  2200] loss: 0.441\n",
      "[6,  2400] loss: 0.393\n",
      "[6,  2600] loss: 0.428\n",
      "[6,  2800] loss: 0.425\n",
      "[6,  3000] loss: 0.410\n",
      "[6,  3200] loss: 0.407\n",
      "[6,  3400] loss: 0.382\n",
      "[6,  3600] loss: 0.416\n",
      "[6,  3800] loss: 0.438\n",
      "[6,  4000] loss: 0.451\n",
      "[6,  4200] loss: 0.454\n",
      "[6,  4400] loss: 0.435\n",
      "[6,  4600] loss: 0.415\n",
      "[6,  4800] loss: 0.398\n",
      "[6,  5000] loss: 0.414\n",
      "[6,  5200] loss: 0.428\n",
      "[6,  5400] loss: 0.447\n",
      "[6,  5600] loss: 0.417\n",
      "[6,  5800] loss: 0.451\n",
      "[6,  6000] loss: 0.443\n",
      "[6,  6200] loss: 0.427\n",
      "[6,  6400] loss: 0.483\n",
      "[6,  6600] loss: 0.405\n",
      "[6,  6800] loss: 0.452\n",
      "[6,  7000] loss: 0.442\n",
      "[6,  7200] loss: 0.510\n",
      "[6,  7400] loss: 0.414\n",
      "[6,  7600] loss: 0.376\n",
      "[6,  7800] loss: 0.438\n",
      "[6,  8000] loss: 0.446\n",
      "[6,  8200] loss: 0.466\n",
      "[6,  8400] loss: 0.463\n",
      "[6,  8600] loss: 0.492\n",
      "[6,  8800] loss: 0.431\n",
      "[6,  9000] loss: 0.400\n",
      "[6,  9200] loss: 0.434\n",
      "[6,  9400] loss: 0.421\n",
      "[6,  9600] loss: 0.456\n",
      "[6,  9800] loss: 0.363\n",
      "[6, 10000] loss: 0.456\n",
      "[7,   200] loss: 0.392\n",
      "[7,   400] loss: 0.408\n",
      "[7,   600] loss: 0.411\n",
      "[7,   800] loss: 0.424\n",
      "[7,  1000] loss: 0.419\n",
      "[7,  1200] loss: 0.392\n",
      "[7,  1400] loss: 0.416\n",
      "[7,  1600] loss: 0.437\n",
      "[7,  1800] loss: 0.389\n",
      "[7,  2000] loss: 0.414\n",
      "[7,  2200] loss: 0.417\n",
      "[7,  2400] loss: 0.425\n",
      "[7,  2600] loss: 0.438\n",
      "[7,  2800] loss: 0.425\n",
      "[7,  3000] loss: 0.446\n",
      "[7,  3200] loss: 0.432\n",
      "[7,  3400] loss: 0.400\n",
      "[7,  3600] loss: 0.406\n",
      "[7,  3800] loss: 0.384\n",
      "[7,  4000] loss: 0.399\n",
      "[7,  4200] loss: 0.417\n",
      "[7,  4400] loss: 0.392\n",
      "[7,  4600] loss: 0.388\n",
      "[7,  4800] loss: 0.399\n",
      "[7,  5000] loss: 0.361\n",
      "[7,  5200] loss: 0.420\n",
      "[7,  5400] loss: 0.428\n",
      "[7,  5600] loss: 0.391\n",
      "[7,  5800] loss: 0.445\n",
      "[7,  6000] loss: 0.425\n",
      "[7,  6200] loss: 0.426\n",
      "[7,  6400] loss: 0.429\n",
      "[7,  6600] loss: 0.408\n",
      "[7,  6800] loss: 0.448\n",
      "[7,  7000] loss: 0.387\n",
      "[7,  7200] loss: 0.459\n",
      "[7,  7400] loss: 0.425\n",
      "[7,  7600] loss: 0.476\n",
      "[7,  7800] loss: 0.363\n",
      "[7,  8000] loss: 0.444\n",
      "[7,  8200] loss: 0.422\n",
      "[7,  8400] loss: 0.416\n",
      "[7,  8600] loss: 0.456\n",
      "[7,  8800] loss: 0.464\n",
      "[7,  9000] loss: 0.469\n",
      "[7,  9200] loss: 0.499\n",
      "[7,  9400] loss: 0.414\n",
      "[7,  9600] loss: 0.399\n",
      "[7,  9800] loss: 0.417\n",
      "[7, 10000] loss: 0.407\n",
      "[8,   200] loss: 0.340\n",
      "[8,   400] loss: 0.380\n",
      "[8,   600] loss: 0.428\n",
      "[8,   800] loss: 0.363\n",
      "[8,  1000] loss: 0.354\n",
      "[8,  1200] loss: 0.385\n",
      "[8,  1400] loss: 0.372\n",
      "[8,  1600] loss: 0.406\n",
      "[8,  1800] loss: 0.400\n",
      "[8,  2000] loss: 0.402\n",
      "[8,  2200] loss: 0.479\n",
      "[8,  2400] loss: 0.388\n",
      "[8,  2600] loss: 0.406\n",
      "[8,  2800] loss: 0.412\n",
      "[8,  3000] loss: 0.375\n",
      "[8,  3200] loss: 0.425\n",
      "[8,  3400] loss: 0.415\n",
      "[8,  3600] loss: 0.457\n",
      "[8,  3800] loss: 0.427\n",
      "[8,  4000] loss: 0.449\n",
      "[8,  4200] loss: 0.403\n",
      "[8,  4400] loss: 0.377\n",
      "[8,  4600] loss: 0.404\n",
      "[8,  4800] loss: 0.396\n",
      "[8,  5000] loss: 0.413\n",
      "[8,  5200] loss: 0.443\n",
      "[8,  5400] loss: 0.336\n",
      "[8,  5600] loss: 0.445\n",
      "[8,  5800] loss: 0.425\n",
      "[8,  6000] loss: 0.383\n",
      "[8,  6200] loss: 0.386\n",
      "[8,  6400] loss: 0.395\n",
      "[8,  6600] loss: 0.365\n",
      "[8,  6800] loss: 0.487\n",
      "[8,  7000] loss: 0.413\n",
      "[8,  7200] loss: 0.367\n",
      "[8,  7400] loss: 0.411\n",
      "[8,  7600] loss: 0.376\n",
      "[8,  7800] loss: 0.377\n",
      "[8,  8000] loss: 0.436\n",
      "[8,  8200] loss: 0.423\n",
      "[8,  8400] loss: 0.387\n",
      "[8,  8600] loss: 0.386\n",
      "[8,  8800] loss: 0.418\n",
      "[8,  9000] loss: 0.407\n",
      "[8,  9200] loss: 0.408\n",
      "[8,  9400] loss: 0.408\n",
      "[8,  9600] loss: 0.378\n",
      "[8,  9800] loss: 0.404\n",
      "[8, 10000] loss: 0.428\n",
      "[9,   200] loss: 0.393\n",
      "[9,   400] loss: 0.393\n",
      "[9,   600] loss: 0.424\n",
      "[9,   800] loss: 0.410\n",
      "[9,  1000] loss: 0.374\n",
      "[9,  1200] loss: 0.375\n",
      "[9,  1400] loss: 0.362\n",
      "[9,  1600] loss: 0.381\n",
      "[9,  1800] loss: 0.395\n",
      "[9,  2000] loss: 0.450\n",
      "[9,  2200] loss: 0.435\n",
      "[9,  2400] loss: 0.443\n",
      "[9,  2600] loss: 0.445\n",
      "[9,  2800] loss: 0.411\n",
      "[9,  3000] loss: 0.328\n",
      "[9,  3200] loss: 0.414\n",
      "[9,  3400] loss: 0.389\n",
      "[9,  3600] loss: 0.367\n",
      "[9,  3800] loss: 0.384\n",
      "[9,  4000] loss: 0.371\n",
      "[9,  4200] loss: 0.388\n",
      "[9,  4400] loss: 0.421\n",
      "[9,  4600] loss: 0.355\n",
      "[9,  4800] loss: 0.420\n",
      "[9,  5000] loss: 0.375\n",
      "[9,  5200] loss: 0.408\n",
      "[9,  5400] loss: 0.457\n",
      "[9,  5600] loss: 0.424\n",
      "[9,  5800] loss: 0.431\n",
      "[9,  6000] loss: 0.350\n",
      "[9,  6200] loss: 0.388\n",
      "[9,  6400] loss: 0.382\n",
      "[9,  6600] loss: 0.357\n",
      "[9,  6800] loss: 0.384\n",
      "[9,  7000] loss: 0.378\n",
      "[9,  7200] loss: 0.418\n",
      "[9,  7400] loss: 0.385\n",
      "[9,  7600] loss: 0.394\n",
      "[9,  7800] loss: 0.404\n",
      "[9,  8000] loss: 0.383\n",
      "[9,  8200] loss: 0.457\n",
      "[9,  8400] loss: 0.386\n",
      "[9,  8600] loss: 0.398\n",
      "[9,  8800] loss: 0.380\n",
      "[9,  9000] loss: 0.394\n",
      "[9,  9200] loss: 0.326\n",
      "[9,  9400] loss: 0.343\n",
      "[9,  9600] loss: 0.390\n",
      "[9,  9800] loss: 0.424\n",
      "[9, 10000] loss: 0.402\n",
      "[10,   200] loss: 0.352\n",
      "[10,   400] loss: 0.337\n",
      "[10,   600] loss: 0.353\n",
      "[10,   800] loss: 0.379\n",
      "[10,  1000] loss: 0.353\n",
      "[10,  1200] loss: 0.418\n",
      "[10,  1400] loss: 0.388\n",
      "[10,  1600] loss: 0.364\n",
      "[10,  1800] loss: 0.384\n",
      "[10,  2000] loss: 0.382\n",
      "[10,  2200] loss: 0.357\n",
      "[10,  2400] loss: 0.358\n",
      "[10,  2600] loss: 0.376\n",
      "[10,  2800] loss: 0.371\n",
      "[10,  3000] loss: 0.351\n",
      "[10,  3200] loss: 0.354\n",
      "[10,  3400] loss: 0.396\n",
      "[10,  3600] loss: 0.430\n",
      "[10,  3800] loss: 0.360\n",
      "[10,  4000] loss: 0.401\n",
      "[10,  4200] loss: 0.345\n",
      "[10,  4400] loss: 0.381\n",
      "[10,  4600] loss: 0.379\n",
      "[10,  4800] loss: 0.369\n",
      "[10,  5000] loss: 0.368\n",
      "[10,  5200] loss: 0.374\n",
      "[10,  5400] loss: 0.392\n",
      "[10,  5600] loss: 0.356\n",
      "[10,  5800] loss: 0.404\n",
      "[10,  6000] loss: 0.363\n",
      "[10,  6200] loss: 0.389\n",
      "[10,  6400] loss: 0.374\n",
      "[10,  6600] loss: 0.428\n",
      "[10,  6800] loss: 0.356\n",
      "[10,  7000] loss: 0.346\n",
      "[10,  7200] loss: 0.352\n",
      "[10,  7400] loss: 0.381\n",
      "[10,  7600] loss: 0.403\n",
      "[10,  7800] loss: 0.356\n",
      "[10,  8000] loss: 0.417\n",
      "[10,  8200] loss: 0.357\n",
      "[10,  8400] loss: 0.398\n",
      "[10,  8600] loss: 0.392\n",
      "[10,  8800] loss: 0.397\n",
      "[10,  9000] loss: 0.430\n",
      "[10,  9200] loss: 0.367\n",
      "[10,  9400] loss: 0.431\n",
      "[10,  9600] loss: 0.371\n",
      "[10,  9800] loss: 0.427\n",
      "[10, 10000] loss: 0.361\n",
      "Finished Additional Training\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "additional_epochs = 5  # Number of additional epochs to train\n",
    "\n",
    "for epoch in range(5, 5 + additional_epochs):  # Continue from epoch 10 to 30\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 200 == 199:\n",
    "            print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 200))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Additional Training')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 83 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
