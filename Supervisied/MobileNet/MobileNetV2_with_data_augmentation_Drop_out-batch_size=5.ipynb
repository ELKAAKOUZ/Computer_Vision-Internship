{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MobileNetV2 in Cifar10 with Augmentation and Dropout Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries,Training,Testing Datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "transform_Training = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "transform_Testing = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    \n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_Training)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_Testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Test Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=5, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=5, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building The Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes, expansion, stride):\n",
    "        super(Block, self).__init__()\n",
    "        self.stride = stride\n",
    "\n",
    "        planes = expansion * in_planes\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, groups=planes, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, out_planes, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(out_planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride == 1 and in_planes != out_planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "                nn.BatchNorm2d(out_planes),\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        out = out + self.shortcut(x) if self.stride==1 else out\n",
    "        return out\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MobileNetV2(nn.Module):\n",
    "    def __init__(self, num_classes=10, dropout_prob=0.5):  # Add dropout_prob parameter\n",
    "        super(MobileNetV2, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.layers = self._make_layers(in_planes=32)\n",
    "        self.conv2 = nn.Conv2d(320, 1280, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(1280)\n",
    "        self.linear = nn.Linear(1280, num_classes)\n",
    "        self.dropout = nn.Dropout(dropout_prob)  # Add dropout layer\n",
    "\n",
    "    def _make_layers(self, in_planes):\n",
    "        cfg = [(1, 16, 1, 1),\n",
    "               (6, 24, 2, 1),  \n",
    "               (6, 32, 3, 2),\n",
    "               (6, 64, 4, 2),\n",
    "               (6, 96, 3, 1),\n",
    "               (6, 160, 3, 2),\n",
    "               (6, 320, 1, 1)]\n",
    "        layers = []\n",
    "        for expansion, out_planes, num_blocks, stride in cfg:\n",
    "            strides = [stride] + [1]*(num_blocks-1)\n",
    "            for stride in strides:\n",
    "                layers.append(Block(in_planes, out_planes, expansion, stride))\n",
    "                in_planes = out_planes\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layers(out)\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.dropout(out)  # Apply dropout\n",
    "        out = self.linear(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 10])\n"
     ]
    }
   ],
   "source": [
    "def test():\n",
    "    net = MobileNetV2()\n",
    "    x = torch.randn(2, 3, 32, 32)  \n",
    "    y = net(x)\n",
    "    print(y.size()) \n",
    "\n",
    "test()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer,Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = MobileNetV2(num_classes=10)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   200] loss: 2.373\n",
      "[1,   400] loss: 2.271\n",
      "[1,   600] loss: 2.168\n",
      "[1,   800] loss: 2.124\n",
      "[1,  1000] loss: 2.190\n",
      "[1,  1200] loss: 2.110\n",
      "[1,  1400] loss: 2.122\n",
      "[1,  1600] loss: 2.131\n",
      "[1,  1800] loss: 2.070\n",
      "[1,  2000] loss: 2.090\n",
      "[1,  2200] loss: 2.041\n",
      "[1,  2400] loss: 2.020\n",
      "[1,  2600] loss: 2.035\n",
      "[1,  2800] loss: 2.034\n",
      "[1,  3000] loss: 2.055\n",
      "[1,  3200] loss: 2.018\n",
      "[1,  3400] loss: 1.943\n",
      "[1,  3600] loss: 1.935\n",
      "[1,  3800] loss: 1.916\n",
      "[1,  4000] loss: 1.969\n",
      "[1,  4200] loss: 1.920\n",
      "[1,  4400] loss: 1.888\n",
      "[1,  4600] loss: 1.891\n",
      "[1,  4800] loss: 1.870\n",
      "[1,  5000] loss: 1.844\n",
      "[1,  5200] loss: 1.830\n",
      "[1,  5400] loss: 1.839\n",
      "[1,  5600] loss: 1.904\n",
      "[1,  5800] loss: 1.840\n",
      "[1,  6000] loss: 1.815\n",
      "[1,  6200] loss: 1.788\n",
      "[1,  6400] loss: 1.849\n",
      "[1,  6600] loss: 1.764\n",
      "[1,  6800] loss: 1.748\n",
      "[1,  7000] loss: 1.757\n",
      "[1,  7200] loss: 1.812\n",
      "[1,  7400] loss: 1.758\n",
      "[1,  7600] loss: 1.686\n",
      "[1,  7800] loss: 1.776\n",
      "[1,  8000] loss: 1.640\n",
      "[1,  8200] loss: 1.788\n",
      "[1,  8400] loss: 1.695\n",
      "[1,  8600] loss: 1.699\n",
      "[1,  8800] loss: 1.631\n",
      "[1,  9000] loss: 1.679\n",
      "[1,  9200] loss: 1.647\n",
      "[1,  9400] loss: 1.614\n",
      "[1,  9600] loss: 1.602\n",
      "[1,  9800] loss: 1.665\n",
      "[1, 10000] loss: 1.609\n",
      "[2,   200] loss: 1.627\n",
      "[2,   400] loss: 1.616\n",
      "[2,   600] loss: 1.508\n",
      "[2,   800] loss: 1.591\n",
      "[2,  1000] loss: 1.557\n",
      "[2,  1200] loss: 1.532\n",
      "[2,  1400] loss: 1.525\n",
      "[2,  1600] loss: 1.569\n",
      "[2,  1800] loss: 1.531\n",
      "[2,  2000] loss: 1.421\n",
      "[2,  2200] loss: 1.505\n",
      "[2,  2400] loss: 1.418\n",
      "[2,  2600] loss: 1.553\n",
      "[2,  2800] loss: 1.456\n",
      "[2,  3000] loss: 1.558\n",
      "[2,  3200] loss: 1.489\n",
      "[2,  3400] loss: 1.442\n",
      "[2,  3600] loss: 1.501\n",
      "[2,  3800] loss: 1.452\n",
      "[2,  4000] loss: 1.483\n",
      "[2,  4200] loss: 1.400\n",
      "[2,  4400] loss: 1.373\n",
      "[2,  4600] loss: 1.479\n",
      "[2,  4800] loss: 1.401\n",
      "[2,  5000] loss: 1.422\n",
      "[2,  5200] loss: 1.349\n",
      "[2,  5400] loss: 1.361\n",
      "[2,  5600] loss: 1.347\n",
      "[2,  5800] loss: 1.390\n",
      "[2,  6000] loss: 1.376\n",
      "[2,  6200] loss: 1.400\n",
      "[2,  6400] loss: 1.459\n",
      "[2,  6600] loss: 1.340\n",
      "[2,  6800] loss: 1.360\n",
      "[2,  7000] loss: 1.355\n",
      "[2,  7200] loss: 1.393\n",
      "[2,  7400] loss: 1.338\n",
      "[2,  7600] loss: 1.379\n",
      "[2,  7800] loss: 1.329\n",
      "[2,  8000] loss: 1.334\n",
      "[2,  8200] loss: 1.274\n",
      "[2,  8400] loss: 1.373\n",
      "[2,  8600] loss: 1.318\n",
      "[2,  8800] loss: 1.356\n",
      "[2,  9000] loss: 1.341\n",
      "[2,  9200] loss: 1.279\n",
      "[2,  9400] loss: 1.258\n",
      "[2,  9600] loss: 1.261\n",
      "[2,  9800] loss: 1.255\n",
      "[2, 10000] loss: 1.288\n",
      "[3,   200] loss: 1.210\n",
      "[3,   400] loss: 1.200\n",
      "[3,   600] loss: 1.286\n",
      "[3,   800] loss: 1.297\n",
      "[3,  1000] loss: 1.255\n",
      "[3,  1200] loss: 1.187\n",
      "[3,  1400] loss: 1.272\n",
      "[3,  1600] loss: 1.275\n",
      "[3,  1800] loss: 1.229\n",
      "[3,  2000] loss: 1.205\n",
      "[3,  2200] loss: 1.241\n",
      "[3,  2400] loss: 1.215\n",
      "[3,  2600] loss: 1.251\n",
      "[3,  2800] loss: 1.282\n",
      "[3,  3000] loss: 1.238\n",
      "[3,  3200] loss: 1.138\n",
      "[3,  3400] loss: 1.255\n",
      "[3,  3600] loss: 1.278\n",
      "[3,  3800] loss: 1.223\n",
      "[3,  4000] loss: 1.175\n",
      "[3,  4200] loss: 1.121\n",
      "[3,  4400] loss: 1.217\n",
      "[3,  4600] loss: 1.149\n",
      "[3,  4800] loss: 1.129\n",
      "[3,  5000] loss: 1.216\n",
      "[3,  5200] loss: 1.147\n",
      "[3,  5400] loss: 1.093\n",
      "[3,  5600] loss: 1.209\n",
      "[3,  5800] loss: 1.187\n",
      "[3,  6000] loss: 1.104\n",
      "[3,  6200] loss: 1.047\n",
      "[3,  6400] loss: 1.060\n",
      "[3,  6600] loss: 1.124\n",
      "[3,  6800] loss: 1.111\n",
      "[3,  7000] loss: 1.102\n",
      "[3,  7200] loss: 1.209\n",
      "[3,  7400] loss: 1.106\n",
      "[3,  7600] loss: 1.114\n",
      "[3,  7800] loss: 1.158\n",
      "[3,  8000] loss: 1.125\n",
      "[3,  8200] loss: 1.134\n",
      "[3,  8400] loss: 1.063\n",
      "[3,  8600] loss: 1.139\n",
      "[3,  8800] loss: 1.123\n",
      "[3,  9000] loss: 1.078\n",
      "[3,  9200] loss: 1.012\n",
      "[3,  9400] loss: 1.058\n",
      "[3,  9600] loss: 1.095\n",
      "[3,  9800] loss: 1.050\n",
      "[3, 10000] loss: 1.043\n",
      "[4,   200] loss: 1.031\n",
      "[4,   400] loss: 1.087\n",
      "[4,   600] loss: 1.019\n",
      "[4,   800] loss: 1.010\n",
      "[4,  1000] loss: 1.043\n",
      "[4,  1200] loss: 0.991\n",
      "[4,  1400] loss: 1.194\n",
      "[4,  1600] loss: 1.050\n",
      "[4,  1800] loss: 1.053\n",
      "[4,  2000] loss: 1.030\n",
      "[4,  2200] loss: 1.027\n",
      "[4,  2400] loss: 1.071\n",
      "[4,  2600] loss: 1.004\n",
      "[4,  2800] loss: 0.969\n",
      "[4,  3000] loss: 0.951\n",
      "[4,  3200] loss: 1.038\n",
      "[4,  3400] loss: 1.016\n",
      "[4,  3600] loss: 1.041\n",
      "[4,  3800] loss: 1.028\n",
      "[4,  4000] loss: 1.024\n",
      "[4,  4200] loss: 0.996\n",
      "[4,  4400] loss: 0.977\n",
      "[4,  4600] loss: 0.976\n",
      "[4,  4800] loss: 0.996\n",
      "[4,  5000] loss: 1.054\n",
      "[4,  5200] loss: 1.021\n",
      "[4,  5400] loss: 0.948\n",
      "[4,  5600] loss: 0.975\n",
      "[4,  5800] loss: 0.967\n",
      "[4,  6000] loss: 0.965\n",
      "[4,  6200] loss: 1.041\n",
      "[4,  6400] loss: 0.938\n",
      "[4,  6600] loss: 1.067\n",
      "[4,  6800] loss: 1.025\n",
      "[4,  7000] loss: 0.918\n",
      "[4,  7200] loss: 1.046\n",
      "[4,  7400] loss: 1.012\n",
      "[4,  7600] loss: 0.980\n",
      "[4,  7800] loss: 0.944\n",
      "[4,  8000] loss: 0.942\n",
      "[4,  8200] loss: 0.960\n",
      "[4,  8400] loss: 0.916\n",
      "[4,  8600] loss: 0.939\n",
      "[4,  8800] loss: 0.926\n",
      "[4,  9000] loss: 1.001\n",
      "[4,  9200] loss: 0.965\n",
      "[4,  9400] loss: 1.058\n",
      "[4,  9600] loss: 0.916\n",
      "[4,  9800] loss: 1.014\n",
      "[4, 10000] loss: 0.957\n",
      "[5,   200] loss: 0.935\n",
      "[5,   400] loss: 0.975\n",
      "[5,   600] loss: 0.863\n",
      "[5,   800] loss: 0.932\n",
      "[5,  1000] loss: 1.003\n",
      "[5,  1200] loss: 0.993\n",
      "[5,  1400] loss: 0.865\n",
      "[5,  1600] loss: 0.963\n",
      "[5,  1800] loss: 0.870\n",
      "[5,  2000] loss: 0.899\n",
      "[5,  2200] loss: 0.893\n",
      "[5,  2400] loss: 0.893\n",
      "[5,  2600] loss: 0.944\n",
      "[5,  2800] loss: 0.883\n",
      "[5,  3000] loss: 0.896\n",
      "[5,  3200] loss: 0.879\n",
      "[5,  3400] loss: 0.919\n",
      "[5,  3600] loss: 0.950\n",
      "[5,  3800] loss: 0.853\n",
      "[5,  4000] loss: 0.933\n",
      "[5,  4200] loss: 0.910\n",
      "[5,  4400] loss: 0.891\n",
      "[5,  4600] loss: 0.895\n",
      "[5,  4800] loss: 0.929\n",
      "[5,  5000] loss: 0.926\n",
      "[5,  5200] loss: 0.899\n",
      "[5,  5400] loss: 0.880\n",
      "[5,  5600] loss: 0.841\n",
      "[5,  5800] loss: 0.881\n",
      "[5,  6000] loss: 0.842\n",
      "[5,  6200] loss: 0.871\n",
      "[5,  6400] loss: 0.888\n",
      "[5,  6600] loss: 0.776\n",
      "[5,  6800] loss: 0.896\n",
      "[5,  7000] loss: 0.888\n",
      "[5,  7200] loss: 0.928\n",
      "[5,  7400] loss: 0.804\n",
      "[5,  7600] loss: 0.863\n",
      "[5,  7800] loss: 0.889\n",
      "[5,  8000] loss: 0.836\n",
      "[5,  8200] loss: 0.812\n",
      "[5,  8400] loss: 0.849\n",
      "[5,  8600] loss: 0.931\n",
      "[5,  8800] loss: 0.835\n",
      "[5,  9000] loss: 0.852\n",
      "[5,  9200] loss: 0.784\n",
      "[5,  9400] loss: 0.894\n",
      "[5,  9600] loss: 0.749\n",
      "[5,  9800] loss: 0.926\n",
      "[5, 10000] loss: 0.805\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(5):  \n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 200 == 199:    \n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 200))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 69 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6,   200] loss: 0.816\n",
      "[6,   400] loss: 0.803\n",
      "[6,   600] loss: 0.772\n",
      "[6,   800] loss: 0.831\n",
      "[6,  1000] loss: 0.836\n",
      "[6,  1200] loss: 0.768\n",
      "[6,  1400] loss: 0.795\n",
      "[6,  1600] loss: 0.794\n",
      "[6,  1800] loss: 0.826\n",
      "[6,  2000] loss: 0.866\n",
      "[6,  2200] loss: 0.836\n",
      "[6,  2400] loss: 0.777\n",
      "[6,  2600] loss: 0.812\n",
      "[6,  2800] loss: 0.766\n",
      "[6,  3000] loss: 0.798\n",
      "[6,  3200] loss: 0.798\n",
      "[6,  3400] loss: 0.812\n",
      "[6,  3600] loss: 0.808\n",
      "[6,  3800] loss: 0.793\n",
      "[6,  4000] loss: 0.782\n",
      "[6,  4200] loss: 0.821\n",
      "[6,  4400] loss: 0.906\n",
      "[6,  4600] loss: 0.807\n",
      "[6,  4800] loss: 0.813\n",
      "[6,  5000] loss: 0.742\n",
      "[6,  5200] loss: 0.791\n",
      "[6,  5400] loss: 0.741\n",
      "[6,  5600] loss: 0.872\n",
      "[6,  5800] loss: 0.788\n",
      "[6,  6000] loss: 0.825\n",
      "[6,  6200] loss: 0.773\n",
      "[6,  6400] loss: 0.813\n",
      "[6,  6600] loss: 0.888\n",
      "[6,  6800] loss: 0.912\n",
      "[6,  7000] loss: 0.814\n",
      "[6,  7200] loss: 0.755\n",
      "[6,  7400] loss: 0.792\n",
      "[6,  7600] loss: 0.789\n",
      "[6,  7800] loss: 0.783\n",
      "[6,  8000] loss: 0.806\n",
      "[6,  8200] loss: 0.860\n",
      "[6,  8400] loss: 0.825\n",
      "[6,  8600] loss: 0.769\n",
      "[6,  8800] loss: 0.824\n",
      "[6,  9000] loss: 0.740\n",
      "[6,  9200] loss: 0.793\n",
      "[6,  9400] loss: 0.831\n",
      "[6,  9600] loss: 0.819\n",
      "[6,  9800] loss: 0.768\n",
      "[6, 10000] loss: 0.797\n",
      "[7,   200] loss: 0.821\n",
      "[7,   400] loss: 0.716\n",
      "[7,   600] loss: 0.741\n",
      "[7,   800] loss: 0.770\n",
      "[7,  1000] loss: 0.775\n",
      "[7,  1200] loss: 0.702\n",
      "[7,  1400] loss: 0.735\n",
      "[7,  1600] loss: 0.830\n",
      "[7,  1800] loss: 0.740\n",
      "[7,  2000] loss: 0.759\n",
      "[7,  2200] loss: 0.785\n",
      "[7,  2400] loss: 0.845\n",
      "[7,  2600] loss: 0.704\n",
      "[7,  2800] loss: 0.715\n",
      "[7,  3000] loss: 0.829\n",
      "[7,  3200] loss: 0.774\n",
      "[7,  3400] loss: 0.738\n",
      "[7,  3600] loss: 0.762\n",
      "[7,  3800] loss: 0.698\n",
      "[7,  4000] loss: 0.738\n",
      "[7,  4200] loss: 0.717\n",
      "[7,  4400] loss: 0.702\n",
      "[7,  4600] loss: 0.756\n",
      "[7,  4800] loss: 0.734\n",
      "[7,  5000] loss: 0.758\n",
      "[7,  5200] loss: 0.733\n",
      "[7,  5400] loss: 0.723\n",
      "[7,  5600] loss: 0.769\n",
      "[7,  5800] loss: 0.778\n",
      "[7,  6000] loss: 0.705\n",
      "[7,  6200] loss: 0.740\n",
      "[7,  6400] loss: 0.738\n",
      "[7,  6600] loss: 0.742\n",
      "[7,  6800] loss: 0.740\n",
      "[7,  7000] loss: 0.708\n",
      "[7,  7200] loss: 0.782\n",
      "[7,  7400] loss: 0.701\n",
      "[7,  7600] loss: 0.751\n",
      "[7,  7800] loss: 0.762\n",
      "[7,  8000] loss: 0.748\n",
      "[7,  8200] loss: 0.740\n",
      "[7,  8400] loss: 0.743\n",
      "[7,  8600] loss: 0.745\n",
      "[7,  8800] loss: 0.711\n",
      "[7,  9000] loss: 0.720\n",
      "[7,  9200] loss: 0.670\n",
      "[7,  9400] loss: 0.712\n",
      "[7,  9600] loss: 0.705\n",
      "[7,  9800] loss: 0.716\n",
      "[7, 10000] loss: 0.742\n",
      "[8,   200] loss: 0.705\n",
      "[8,   400] loss: 0.698\n",
      "[8,   600] loss: 0.708\n",
      "[8,   800] loss: 0.650\n",
      "[8,  1000] loss: 0.714\n",
      "[8,  1200] loss: 0.740\n",
      "[8,  1400] loss: 0.712\n",
      "[8,  1600] loss: 0.746\n",
      "[8,  1800] loss: 0.684\n",
      "[8,  2000] loss: 0.692\n",
      "[8,  2200] loss: 0.673\n",
      "[8,  2400] loss: 0.723\n",
      "[8,  2600] loss: 0.755\n",
      "[8,  2800] loss: 0.738\n",
      "[8,  3000] loss: 0.678\n",
      "[8,  3200] loss: 0.674\n",
      "[8,  3400] loss: 0.700\n",
      "[8,  3600] loss: 0.734\n",
      "[8,  3800] loss: 0.739\n",
      "[8,  4000] loss: 0.679\n",
      "[8,  4200] loss: 0.680\n",
      "[8,  4400] loss: 0.721\n",
      "[8,  4600] loss: 0.704\n",
      "[8,  4800] loss: 0.707\n",
      "[8,  5000] loss: 0.697\n",
      "[8,  5200] loss: 0.690\n",
      "[8,  5400] loss: 0.697\n",
      "[8,  5600] loss: 0.670\n",
      "[8,  5800] loss: 0.650\n",
      "[8,  6000] loss: 0.752\n",
      "[8,  6200] loss: 0.690\n",
      "[8,  6400] loss: 0.681\n",
      "[8,  6600] loss: 0.701\n",
      "[8,  6800] loss: 0.667\n",
      "[8,  7000] loss: 0.667\n",
      "[8,  7200] loss: 0.736\n",
      "[8,  7400] loss: 0.675\n",
      "[8,  7600] loss: 0.660\n",
      "[8,  7800] loss: 0.670\n",
      "[8,  8000] loss: 0.719\n",
      "[8,  8200] loss: 0.651\n",
      "[8,  8400] loss: 0.709\n",
      "[8,  8600] loss: 0.583\n",
      "[8,  8800] loss: 0.662\n",
      "[8,  9000] loss: 0.627\n",
      "[8,  9200] loss: 0.656\n",
      "[8,  9400] loss: 0.681\n",
      "[8,  9600] loss: 0.707\n",
      "[8,  9800] loss: 0.628\n",
      "[8, 10000] loss: 0.722\n",
      "[9,   200] loss: 0.637\n",
      "[9,   400] loss: 0.632\n",
      "[9,   600] loss: 0.686\n",
      "[9,   800] loss: 0.691\n",
      "[9,  1000] loss: 0.674\n",
      "[9,  1200] loss: 0.601\n",
      "[9,  1400] loss: 0.717\n",
      "[9,  1600] loss: 0.650\n",
      "[9,  1800] loss: 0.637\n",
      "[9,  2000] loss: 0.628\n",
      "[9,  2200] loss: 0.665\n",
      "[9,  2400] loss: 0.594\n",
      "[9,  2600] loss: 0.705\n",
      "[9,  2800] loss: 0.683\n",
      "[9,  3000] loss: 0.626\n",
      "[9,  3200] loss: 0.627\n",
      "[9,  3400] loss: 0.673\n",
      "[9,  3600] loss: 0.684\n",
      "[9,  3800] loss: 0.643\n",
      "[9,  4000] loss: 0.716\n",
      "[9,  4200] loss: 0.640\n",
      "[9,  4400] loss: 0.697\n",
      "[9,  4600] loss: 0.635\n",
      "[9,  4800] loss: 0.609\n",
      "[9,  5000] loss: 0.640\n",
      "[9,  5200] loss: 0.652\n",
      "[9,  5400] loss: 0.683\n",
      "[9,  5600] loss: 0.644\n",
      "[9,  5800] loss: 0.646\n",
      "[9,  6000] loss: 0.605\n",
      "[9,  6200] loss: 0.621\n",
      "[9,  6400] loss: 0.671\n",
      "[9,  6600] loss: 0.610\n",
      "[9,  6800] loss: 0.675\n",
      "[9,  7000] loss: 0.622\n",
      "[9,  7200] loss: 0.616\n",
      "[9,  7400] loss: 0.568\n",
      "[9,  7600] loss: 0.612\n",
      "[9,  7800] loss: 0.656\n",
      "[9,  8000] loss: 0.632\n",
      "[9,  8200] loss: 0.702\n",
      "[9,  8400] loss: 0.660\n",
      "[9,  8600] loss: 0.674\n",
      "[9,  8800] loss: 0.629\n",
      "[9,  9000] loss: 0.669\n",
      "[9,  9200] loss: 0.659\n",
      "[9,  9400] loss: 0.643\n",
      "[9,  9600] loss: 0.627\n",
      "[9,  9800] loss: 0.615\n",
      "[9, 10000] loss: 0.634\n",
      "[10,   200] loss: 0.564\n",
      "[10,   400] loss: 0.636\n",
      "[10,   600] loss: 0.624\n",
      "[10,   800] loss: 0.601\n",
      "[10,  1000] loss: 0.651\n",
      "[10,  1200] loss: 0.580\n",
      "[10,  1400] loss: 0.611\n",
      "[10,  1600] loss: 0.604\n",
      "[10,  1800] loss: 0.613\n",
      "[10,  2000] loss: 0.611\n",
      "[10,  2200] loss: 0.652\n",
      "[10,  2400] loss: 0.632\n",
      "[10,  2600] loss: 0.648\n",
      "[10,  2800] loss: 0.634\n",
      "[10,  3000] loss: 0.602\n",
      "[10,  3200] loss: 0.582\n",
      "[10,  3400] loss: 0.577\n",
      "[10,  3600] loss: 0.556\n",
      "[10,  3800] loss: 0.627\n",
      "[10,  4000] loss: 0.633\n",
      "[10,  4200] loss: 0.608\n",
      "[10,  4400] loss: 0.612\n",
      "[10,  4600] loss: 0.601\n",
      "[10,  4800] loss: 0.595\n",
      "[10,  5000] loss: 0.567\n",
      "[10,  5200] loss: 0.585\n",
      "[10,  5400] loss: 0.641\n",
      "[10,  5600] loss: 0.652\n",
      "[10,  5800] loss: 0.598\n",
      "[10,  6000] loss: 0.576\n",
      "[10,  6200] loss: 0.621\n",
      "[10,  6400] loss: 0.658\n",
      "[10,  6600] loss: 0.584\n",
      "[10,  6800] loss: 0.617\n",
      "[10,  7000] loss: 0.667\n",
      "[10,  7200] loss: 0.639\n",
      "[10,  7400] loss: 0.637\n",
      "[10,  7600] loss: 0.558\n",
      "[10,  7800] loss: 0.671\n",
      "[10,  8000] loss: 0.603\n",
      "[10,  8200] loss: 0.603\n",
      "[10,  8400] loss: 0.681\n",
      "[10,  8600] loss: 0.633\n",
      "[10,  8800] loss: 0.584\n",
      "[10,  9000] loss: 0.567\n",
      "[10,  9200] loss: 0.569\n",
      "[10,  9400] loss: 0.633\n",
      "[10,  9600] loss: 0.564\n",
      "[10,  9800] loss: 0.608\n",
      "[10, 10000] loss: 0.557\n",
      "Finished Additional Training\n"
     ]
    }
   ],
   "source": [
    "additional_epochs = 5  # Number of additional epochs to train\n",
    "\n",
    "for epoch in range(5, 5 + additional_epochs):  # Continue from epoch 10 to 30\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 200 == 199:\n",
    "            print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 200))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Additional Training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 77 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6,   200] loss: 0.595\n",
      "[6,   400] loss: 0.573\n",
      "[6,   600] loss: 0.486\n",
      "[6,   800] loss: 0.555\n",
      "[6,  1000] loss: 0.602\n",
      "[6,  1200] loss: 0.564\n",
      "[6,  1400] loss: 0.565\n",
      "[6,  1600] loss: 0.545\n",
      "[6,  1800] loss: 0.649\n",
      "[6,  2000] loss: 0.579\n",
      "[6,  2200] loss: 0.602\n",
      "[6,  2400] loss: 0.579\n",
      "[6,  2600] loss: 0.613\n",
      "[6,  2800] loss: 0.597\n",
      "[6,  3000] loss: 0.638\n",
      "[6,  3200] loss: 0.622\n",
      "[6,  3400] loss: 0.590\n",
      "[6,  3600] loss: 0.638\n",
      "[6,  3800] loss: 0.593\n",
      "[6,  4000] loss: 0.550\n",
      "[6,  4200] loss: 0.542\n",
      "[6,  4400] loss: 0.559\n",
      "[6,  4600] loss: 0.563\n",
      "[6,  4800] loss: 0.535\n",
      "[6,  5000] loss: 0.637\n",
      "[6,  5200] loss: 0.499\n",
      "[6,  5400] loss: 0.582\n",
      "[6,  5600] loss: 0.580\n",
      "[6,  5800] loss: 0.576\n",
      "[6,  6000] loss: 0.622\n",
      "[6,  6200] loss: 0.598\n",
      "[6,  6400] loss: 0.607\n",
      "[6,  6600] loss: 0.617\n",
      "[6,  6800] loss: 0.522\n",
      "[6,  7000] loss: 0.523\n",
      "[6,  7200] loss: 0.579\n",
      "[6,  7400] loss: 0.553\n",
      "[6,  7600] loss: 0.568\n",
      "[6,  7800] loss: 0.584\n",
      "[6,  8000] loss: 0.586\n",
      "[6,  8200] loss: 0.558\n",
      "[6,  8400] loss: 0.548\n",
      "[6,  8600] loss: 0.664\n",
      "[6,  8800] loss: 0.584\n",
      "[6,  9000] loss: 0.587\n",
      "[6,  9200] loss: 0.552\n",
      "[6,  9400] loss: 0.576\n",
      "[6,  9600] loss: 0.527\n",
      "[6,  9800] loss: 0.499\n",
      "[6, 10000] loss: 0.624\n",
      "[7,   200] loss: 0.517\n",
      "[7,   400] loss: 0.571\n",
      "[7,   600] loss: 0.580\n",
      "[7,   800] loss: 0.535\n",
      "[7,  1000] loss: 0.545\n",
      "[7,  1200] loss: 0.480\n",
      "[7,  1400] loss: 0.651\n",
      "[7,  1600] loss: 0.509\n",
      "[7,  1800] loss: 0.510\n",
      "[7,  2000] loss: 0.506\n",
      "[7,  2200] loss: 0.592\n",
      "[7,  2400] loss: 0.587\n",
      "[7,  2600] loss: 0.529\n",
      "[7,  2800] loss: 0.496\n",
      "[7,  3000] loss: 0.595\n",
      "[7,  3200] loss: 0.513\n",
      "[7,  3400] loss: 0.594\n",
      "[7,  3600] loss: 0.582\n",
      "[7,  3800] loss: 0.620\n",
      "[7,  4000] loss: 0.563\n",
      "[7,  4200] loss: 0.513\n",
      "[7,  4400] loss: 0.534\n",
      "[7,  4600] loss: 0.554\n",
      "[7,  4800] loss: 0.538\n",
      "[7,  5000] loss: 0.613\n",
      "[7,  5200] loss: 0.577\n",
      "[7,  5400] loss: 0.504\n",
      "[7,  5600] loss: 0.519\n",
      "[7,  5800] loss: 0.568\n",
      "[7,  6000] loss: 0.585\n",
      "[7,  6200] loss: 0.492\n",
      "[7,  6400] loss: 0.517\n",
      "[7,  6600] loss: 0.529\n",
      "[7,  6800] loss: 0.568\n",
      "[7,  7000] loss: 0.544\n",
      "[7,  7200] loss: 0.543\n",
      "[7,  7400] loss: 0.537\n",
      "[7,  7600] loss: 0.565\n",
      "[7,  7800] loss: 0.555\n",
      "[7,  8000] loss: 0.588\n",
      "[7,  8200] loss: 0.537\n",
      "[7,  8400] loss: 0.543\n",
      "[7,  8600] loss: 0.489\n",
      "[7,  8800] loss: 0.517\n",
      "[7,  9000] loss: 0.586\n",
      "[7,  9200] loss: 0.570\n",
      "[7,  9400] loss: 0.506\n",
      "[7,  9600] loss: 0.504\n",
      "[7,  9800] loss: 0.572\n",
      "[7, 10000] loss: 0.555\n",
      "[8,   200] loss: 0.530\n",
      "[8,   400] loss: 0.558\n",
      "[8,   600] loss: 0.535\n",
      "[8,   800] loss: 0.513\n",
      "[8,  1000] loss: 0.508\n",
      "[8,  1200] loss: 0.563\n",
      "[8,  1400] loss: 0.553\n",
      "[8,  1600] loss: 0.538\n",
      "[8,  1800] loss: 0.509\n",
      "[8,  2000] loss: 0.600\n",
      "[8,  2200] loss: 0.548\n",
      "[8,  2400] loss: 0.495\n",
      "[8,  2600] loss: 0.483\n",
      "[8,  2800] loss: 0.513\n",
      "[8,  3000] loss: 0.548\n",
      "[8,  3200] loss: 0.528\n",
      "[8,  3400] loss: 0.512\n",
      "[8,  3600] loss: 0.568\n",
      "[8,  3800] loss: 0.555\n",
      "[8,  4000] loss: 0.493\n",
      "[8,  4200] loss: 0.537\n",
      "[8,  4400] loss: 0.522\n",
      "[8,  4600] loss: 0.527\n",
      "[8,  4800] loss: 0.503\n",
      "[8,  5000] loss: 0.504\n",
      "[8,  5200] loss: 0.517\n",
      "[8,  5400] loss: 0.516\n",
      "[8,  5600] loss: 0.561\n",
      "[8,  5800] loss: 0.510\n",
      "[8,  6000] loss: 0.501\n",
      "[8,  6200] loss: 0.519\n",
      "[8,  6400] loss: 0.511\n",
      "[8,  6600] loss: 0.520\n",
      "[8,  6800] loss: 0.504\n",
      "[8,  7000] loss: 0.476\n",
      "[8,  7200] loss: 0.541\n",
      "[8,  7400] loss: 0.461\n",
      "[8,  7600] loss: 0.591\n",
      "[8,  7800] loss: 0.520\n",
      "[8,  8000] loss: 0.463\n",
      "[8,  8200] loss: 0.530\n",
      "[8,  8400] loss: 0.515\n",
      "[8,  8600] loss: 0.476\n",
      "[8,  8800] loss: 0.570\n",
      "[8,  9000] loss: 0.489\n",
      "[8,  9200] loss: 0.543\n",
      "[8,  9400] loss: 0.543\n",
      "[8,  9600] loss: 0.536\n",
      "[8,  9800] loss: 0.498\n",
      "[8, 10000] loss: 0.556\n",
      "[9,   200] loss: 0.484\n",
      "[9,   400] loss: 0.525\n",
      "[9,   600] loss: 0.513\n",
      "[9,   800] loss: 0.521\n",
      "[9,  1000] loss: 0.493\n",
      "[9,  1200] loss: 0.506\n",
      "[9,  1400] loss: 0.527\n",
      "[9,  1600] loss: 0.508\n",
      "[9,  1800] loss: 0.524\n",
      "[9,  2000] loss: 0.505\n",
      "[9,  2200] loss: 0.501\n",
      "[9,  2400] loss: 0.527\n",
      "[9,  2600] loss: 0.429\n",
      "[9,  2800] loss: 0.473\n",
      "[9,  3000] loss: 0.478\n",
      "[9,  3200] loss: 0.551\n",
      "[9,  3400] loss: 0.542\n",
      "[9,  3600] loss: 0.502\n",
      "[9,  3800] loss: 0.495\n",
      "[9,  4000] loss: 0.528\n",
      "[9,  4200] loss: 0.505\n",
      "[9,  4400] loss: 0.522\n",
      "[9,  4600] loss: 0.477\n",
      "[9,  4800] loss: 0.484\n",
      "[9,  5000] loss: 0.517\n",
      "[9,  5200] loss: 0.545\n",
      "[9,  5400] loss: 0.498\n",
      "[9,  5600] loss: 0.481\n",
      "[9,  5800] loss: 0.507\n",
      "[9,  6000] loss: 0.491\n",
      "[9,  6200] loss: 0.457\n",
      "[9,  6400] loss: 0.456\n",
      "[9,  6600] loss: 0.465\n",
      "[9,  6800] loss: 0.464\n",
      "[9,  7000] loss: 0.482\n",
      "[9,  7200] loss: 0.507\n",
      "[9,  7400] loss: 0.524\n",
      "[9,  7600] loss: 0.505\n",
      "[9,  7800] loss: 0.491\n",
      "[9,  8000] loss: 0.511\n",
      "[9,  8200] loss: 0.473\n",
      "[9,  8400] loss: 0.513\n",
      "[9,  8600] loss: 0.495\n",
      "[9,  8800] loss: 0.422\n",
      "[9,  9000] loss: 0.515\n",
      "[9,  9200] loss: 0.500\n",
      "[9,  9400] loss: 0.510\n",
      "[9,  9600] loss: 0.532\n",
      "[9,  9800] loss: 0.514\n",
      "[9, 10000] loss: 0.482\n",
      "[10,   200] loss: 0.433\n",
      "[10,   400] loss: 0.462\n",
      "[10,   600] loss: 0.523\n",
      "[10,   800] loss: 0.464\n",
      "[10,  1000] loss: 0.506\n",
      "[10,  1200] loss: 0.471\n",
      "[10,  1400] loss: 0.471\n",
      "[10,  1600] loss: 0.448\n",
      "[10,  1800] loss: 0.491\n",
      "[10,  2000] loss: 0.519\n",
      "[10,  2200] loss: 0.489\n",
      "[10,  2400] loss: 0.464\n",
      "[10,  2600] loss: 0.459\n",
      "[10,  2800] loss: 0.530\n",
      "[10,  3000] loss: 0.522\n",
      "[10,  3200] loss: 0.509\n",
      "[10,  3400] loss: 0.468\n",
      "[10,  3600] loss: 0.533\n",
      "[10,  3800] loss: 0.519\n",
      "[10,  4000] loss: 0.539\n",
      "[10,  4200] loss: 0.513\n",
      "[10,  4400] loss: 0.488\n",
      "[10,  4600] loss: 0.496\n",
      "[10,  4800] loss: 0.457\n",
      "[10,  5000] loss: 0.426\n",
      "[10,  5200] loss: 0.465\n",
      "[10,  5400] loss: 0.495\n",
      "[10,  5600] loss: 0.468\n",
      "[10,  5800] loss: 0.497\n",
      "[10,  6000] loss: 0.458\n",
      "[10,  6200] loss: 0.496\n",
      "[10,  6400] loss: 0.477\n",
      "[10,  6600] loss: 0.479\n",
      "[10,  6800] loss: 0.512\n",
      "[10,  7000] loss: 0.466\n",
      "[10,  7200] loss: 0.510\n",
      "[10,  7400] loss: 0.507\n",
      "[10,  7600] loss: 0.441\n",
      "[10,  7800] loss: 0.485\n",
      "[10,  8000] loss: 0.428\n",
      "[10,  8200] loss: 0.522\n",
      "[10,  8400] loss: 0.519\n",
      "[10,  8600] loss: 0.498\n",
      "[10,  8800] loss: 0.509\n",
      "[10,  9000] loss: 0.399\n",
      "[10,  9200] loss: 0.491\n",
      "[10,  9400] loss: 0.462\n",
      "[10,  9600] loss: 0.498\n",
      "[10,  9800] loss: 0.500\n",
      "[10, 10000] loss: 0.483\n",
      "Finished Additional Training\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "additional_epochs = 5  # Number of additional epochs to train\n",
    "\n",
    "for epoch in range(5, 5 + additional_epochs):  # Continue from epoch 10 to 30\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 200 == 199:\n",
    "            print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 200))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Additional Training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 80 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6,   200] loss: 0.438\n",
      "[6,   400] loss: 0.406\n",
      "[6,   600] loss: 0.499\n",
      "[6,   800] loss: 0.446\n",
      "[6,  1000] loss: 0.438\n",
      "[6,  1200] loss: 0.474\n",
      "[6,  1400] loss: 0.463\n",
      "[6,  1600] loss: 0.475\n",
      "[6,  1800] loss: 0.502\n",
      "[6,  2000] loss: 0.539\n",
      "[6,  2200] loss: 0.493\n",
      "[6,  2400] loss: 0.423\n",
      "[6,  2600] loss: 0.446\n",
      "[6,  2800] loss: 0.498\n",
      "[6,  3000] loss: 0.487\n",
      "[6,  3200] loss: 0.488\n",
      "[6,  3400] loss: 0.413\n",
      "[6,  3600] loss: 0.428\n",
      "[6,  3800] loss: 0.418\n",
      "[6,  4000] loss: 0.460\n",
      "[6,  4200] loss: 0.453\n",
      "[6,  4400] loss: 0.504\n",
      "[6,  4600] loss: 0.449\n",
      "[6,  4800] loss: 0.475\n",
      "[6,  5000] loss: 0.455\n",
      "[6,  5200] loss: 0.452\n",
      "[6,  5400] loss: 0.419\n",
      "[6,  5600] loss: 0.429\n",
      "[6,  5800] loss: 0.422\n",
      "[6,  6000] loss: 0.493\n",
      "[6,  6200] loss: 0.449\n",
      "[6,  6400] loss: 0.501\n",
      "[6,  6600] loss: 0.493\n",
      "[6,  6800] loss: 0.453\n",
      "[6,  7000] loss: 0.487\n",
      "[6,  7200] loss: 0.445\n",
      "[6,  7400] loss: 0.453\n",
      "[6,  7600] loss: 0.480\n",
      "[6,  7800] loss: 0.436\n",
      "[6,  8000] loss: 0.483\n",
      "[6,  8200] loss: 0.442\n",
      "[6,  8400] loss: 0.470\n",
      "[6,  8600] loss: 0.475\n",
      "[6,  8800] loss: 0.452\n",
      "[6,  9000] loss: 0.433\n",
      "[6,  9200] loss: 0.488\n",
      "[6,  9400] loss: 0.461\n",
      "[6,  9600] loss: 0.438\n",
      "[6,  9800] loss: 0.445\n",
      "[6, 10000] loss: 0.468\n",
      "[7,   200] loss: 0.434\n",
      "[7,   400] loss: 0.406\n",
      "[7,   600] loss: 0.383\n",
      "[7,   800] loss: 0.434\n",
      "[7,  1000] loss: 0.430\n",
      "[7,  1200] loss: 0.367\n",
      "[7,  1400] loss: 0.542\n",
      "[7,  1600] loss: 0.443\n",
      "[7,  1800] loss: 0.431\n",
      "[7,  2000] loss: 0.441\n",
      "[7,  2200] loss: 0.486\n",
      "[7,  2400] loss: 0.488\n",
      "[7,  2600] loss: 0.439\n",
      "[7,  2800] loss: 0.500\n",
      "[7,  3000] loss: 0.413\n",
      "[7,  3200] loss: 0.465\n",
      "[7,  3400] loss: 0.451\n",
      "[7,  3600] loss: 0.457\n",
      "[7,  3800] loss: 0.382\n",
      "[7,  4000] loss: 0.431\n",
      "[7,  4200] loss: 0.410\n",
      "[7,  4400] loss: 0.473\n",
      "[7,  4600] loss: 0.403\n",
      "[7,  4800] loss: 0.457\n",
      "[7,  5000] loss: 0.481\n",
      "[7,  5200] loss: 0.407\n",
      "[7,  5400] loss: 0.442\n",
      "[7,  5600] loss: 0.451\n",
      "[7,  5800] loss: 0.486\n",
      "[7,  6000] loss: 0.424\n",
      "[7,  6200] loss: 0.454\n",
      "[7,  6400] loss: 0.427\n",
      "[7,  6600] loss: 0.458\n",
      "[7,  6800] loss: 0.477\n",
      "[7,  7000] loss: 0.444\n",
      "[7,  7200] loss: 0.419\n",
      "[7,  7400] loss: 0.454\n",
      "[7,  7600] loss: 0.461\n",
      "[7,  7800] loss: 0.427\n",
      "[7,  8000] loss: 0.488\n",
      "[7,  8200] loss: 0.460\n",
      "[7,  8400] loss: 0.471\n",
      "[7,  8600] loss: 0.446\n",
      "[7,  8800] loss: 0.412\n",
      "[7,  9000] loss: 0.432\n",
      "[7,  9200] loss: 0.426\n",
      "[7,  9400] loss: 0.448\n",
      "[7,  9600] loss: 0.435\n",
      "[7,  9800] loss: 0.518\n",
      "[7, 10000] loss: 0.434\n",
      "[8,   200] loss: 0.378\n",
      "[8,   400] loss: 0.389\n",
      "[8,   600] loss: 0.366\n",
      "[8,   800] loss: 0.430\n",
      "[8,  1000] loss: 0.408\n",
      "[8,  1200] loss: 0.424\n",
      "[8,  1400] loss: 0.437\n",
      "[8,  1600] loss: 0.442\n",
      "[8,  1800] loss: 0.419\n",
      "[8,  2000] loss: 0.414\n",
      "[8,  2200] loss: 0.413\n",
      "[8,  2400] loss: 0.450\n",
      "[8,  2600] loss: 0.400\n",
      "[8,  2800] loss: 0.413\n",
      "[8,  3000] loss: 0.465\n",
      "[8,  3200] loss: 0.419\n",
      "[8,  3400] loss: 0.400\n",
      "[8,  3600] loss: 0.418\n",
      "[8,  3800] loss: 0.413\n",
      "[8,  4000] loss: 0.419\n",
      "[8,  4200] loss: 0.433\n",
      "[8,  4400] loss: 0.429\n",
      "[8,  4600] loss: 0.399\n",
      "[8,  4800] loss: 0.389\n",
      "[8,  5000] loss: 0.446\n",
      "[8,  5200] loss: 0.453\n",
      "[8,  5400] loss: 0.392\n",
      "[8,  5600] loss: 0.408\n",
      "[8,  5800] loss: 0.435\n",
      "[8,  6000] loss: 0.390\n",
      "[8,  6200] loss: 0.443\n",
      "[8,  6400] loss: 0.434\n",
      "[8,  6600] loss: 0.442\n",
      "[8,  6800] loss: 0.417\n",
      "[8,  7000] loss: 0.393\n",
      "[8,  7200] loss: 0.436\n",
      "[8,  7400] loss: 0.415\n",
      "[8,  7600] loss: 0.445\n",
      "[8,  7800] loss: 0.516\n",
      "[8,  8000] loss: 0.484\n",
      "[8,  8200] loss: 0.453\n",
      "[8,  8400] loss: 0.442\n",
      "[8,  8600] loss: 0.455\n",
      "[8,  8800] loss: 0.385\n",
      "[8,  9000] loss: 0.429\n",
      "[8,  9200] loss: 0.404\n",
      "[8,  9400] loss: 0.477\n",
      "[8,  9600] loss: 0.424\n",
      "[8,  9800] loss: 0.429\n",
      "[8, 10000] loss: 0.454\n",
      "[9,   200] loss: 0.434\n",
      "[9,   400] loss: 0.369\n",
      "[9,   600] loss: 0.379\n",
      "[9,   800] loss: 0.415\n",
      "[9,  1000] loss: 0.399\n",
      "[9,  1200] loss: 0.420\n",
      "[9,  1400] loss: 0.423\n",
      "[9,  1600] loss: 0.409\n",
      "[9,  1800] loss: 0.367\n",
      "[9,  2000] loss: 0.426\n",
      "[9,  2200] loss: 0.370\n",
      "[9,  2400] loss: 0.353\n",
      "[9,  2600] loss: 0.451\n",
      "[9,  2800] loss: 0.412\n",
      "[9,  3000] loss: 0.433\n",
      "[9,  3200] loss: 0.410\n",
      "[9,  3400] loss: 0.501\n",
      "[9,  3600] loss: 0.410\n",
      "[9,  3800] loss: 0.424\n",
      "[9,  4000] loss: 0.398\n",
      "[9,  4200] loss: 0.399\n",
      "[9,  4400] loss: 0.364\n",
      "[9,  4600] loss: 0.451\n",
      "[9,  4800] loss: 0.400\n",
      "[9,  5000] loss: 0.381\n",
      "[9,  5200] loss: 0.449\n",
      "[9,  5400] loss: 0.466\n",
      "[9,  5600] loss: 0.452\n",
      "[9,  5800] loss: 0.444\n",
      "[9,  6000] loss: 0.444\n",
      "[9,  6200] loss: 0.426\n",
      "[9,  6400] loss: 0.382\n",
      "[9,  6600] loss: 0.395\n",
      "[9,  6800] loss: 0.411\n",
      "[9,  7000] loss: 0.422\n",
      "[9,  7200] loss: 0.373\n",
      "[9,  7400] loss: 0.396\n",
      "[9,  7600] loss: 0.415\n",
      "[9,  7800] loss: 0.360\n",
      "[9,  8000] loss: 0.426\n",
      "[9,  8200] loss: 0.387\n",
      "[9,  8400] loss: 0.419\n",
      "[9,  8600] loss: 0.391\n",
      "[9,  8800] loss: 0.400\n",
      "[9,  9000] loss: 0.449\n",
      "[9,  9200] loss: 0.405\n",
      "[9,  9400] loss: 0.399\n",
      "[9,  9600] loss: 0.461\n",
      "[9,  9800] loss: 0.450\n",
      "[9, 10000] loss: 0.431\n",
      "[10,   200] loss: 0.368\n",
      "[10,   400] loss: 0.412\n",
      "[10,   600] loss: 0.344\n",
      "[10,   800] loss: 0.429\n",
      "[10,  1000] loss: 0.399\n",
      "[10,  1200] loss: 0.403\n",
      "[10,  1400] loss: 0.386\n",
      "[10,  1600] loss: 0.381\n",
      "[10,  1800] loss: 0.363\n",
      "[10,  2000] loss: 0.381\n",
      "[10,  2200] loss: 0.375\n",
      "[10,  2400] loss: 0.411\n",
      "[10,  2600] loss: 0.373\n",
      "[10,  2800] loss: 0.415\n",
      "[10,  3000] loss: 0.391\n",
      "[10,  3200] loss: 0.422\n",
      "[10,  3400] loss: 0.415\n",
      "[10,  3600] loss: 0.372\n",
      "[10,  3800] loss: 0.397\n",
      "[10,  4000] loss: 0.404\n",
      "[10,  4200] loss: 0.419\n",
      "[10,  4400] loss: 0.410\n",
      "[10,  4600] loss: 0.403\n",
      "[10,  4800] loss: 0.404\n",
      "[10,  5000] loss: 0.388\n",
      "[10,  5200] loss: 0.423\n",
      "[10,  5400] loss: 0.427\n",
      "[10,  5600] loss: 0.377\n",
      "[10,  5800] loss: 0.415\n",
      "[10,  6000] loss: 0.356\n",
      "[10,  6200] loss: 0.398\n",
      "[10,  6400] loss: 0.401\n",
      "[10,  6600] loss: 0.405\n",
      "[10,  6800] loss: 0.412\n",
      "[10,  7000] loss: 0.410\n",
      "[10,  7200] loss: 0.425\n",
      "[10,  7400] loss: 0.391\n",
      "[10,  7600] loss: 0.407\n",
      "[10,  7800] loss: 0.430\n",
      "[10,  8000] loss: 0.432\n",
      "[10,  8200] loss: 0.434\n",
      "[10,  8400] loss: 0.374\n",
      "[10,  8600] loss: 0.442\n",
      "[10,  8800] loss: 0.403\n",
      "[10,  9000] loss: 0.405\n",
      "[10,  9200] loss: 0.390\n",
      "[10,  9400] loss: 0.410\n",
      "[10,  9600] loss: 0.414\n",
      "[10,  9800] loss: 0.440\n",
      "[10, 10000] loss: 0.383\n",
      "Finished Additional Training\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "additional_epochs = 5  # Number of additional epochs to train\n",
    "\n",
    "for epoch in range(5, 5 + additional_epochs):  # Continue from epoch 10 to 30\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 200 == 199:\n",
    "            print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 200))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Additional Training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 82 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6,   200] loss: 0.378\n",
      "[6,   400] loss: 0.357\n",
      "[6,   600] loss: 0.358\n",
      "[6,   800] loss: 0.391\n",
      "[6,  1000] loss: 0.357\n",
      "[6,  1200] loss: 0.417\n",
      "[6,  1400] loss: 0.389\n",
      "[6,  1600] loss: 0.325\n",
      "[6,  1800] loss: 0.401\n",
      "[6,  2000] loss: 0.383\n",
      "[6,  2200] loss: 0.411\n",
      "[6,  2400] loss: 0.358\n",
      "[6,  2600] loss: 0.362\n",
      "[6,  2800] loss: 0.368\n",
      "[6,  3000] loss: 0.393\n",
      "[6,  3200] loss: 0.379\n",
      "[6,  3400] loss: 0.412\n",
      "[6,  3600] loss: 0.401\n",
      "[6,  3800] loss: 0.342\n",
      "[6,  4000] loss: 0.373\n",
      "[6,  4200] loss: 0.362\n",
      "[6,  4400] loss: 0.381\n",
      "[6,  4600] loss: 0.425\n",
      "[6,  4800] loss: 0.435\n",
      "[6,  5000] loss: 0.389\n",
      "[6,  5200] loss: 0.355\n",
      "[6,  5400] loss: 0.373\n",
      "[6,  5600] loss: 0.398\n",
      "[6,  5800] loss: 0.364\n",
      "[6,  6000] loss: 0.356\n",
      "[6,  6200] loss: 0.429\n",
      "[6,  6400] loss: 0.351\n",
      "[6,  6600] loss: 0.371\n",
      "[6,  6800] loss: 0.337\n",
      "[6,  7000] loss: 0.366\n",
      "[6,  7200] loss: 0.385\n",
      "[6,  7400] loss: 0.416\n",
      "[6,  7600] loss: 0.440\n",
      "[6,  7800] loss: 0.405\n",
      "[6,  8000] loss: 0.342\n",
      "[6,  8200] loss: 0.389\n",
      "[6,  8400] loss: 0.354\n",
      "[6,  8600] loss: 0.436\n",
      "[6,  8800] loss: 0.470\n",
      "[6,  9000] loss: 0.349\n",
      "[6,  9200] loss: 0.378\n",
      "[6,  9400] loss: 0.318\n",
      "[6,  9600] loss: 0.329\n",
      "[6,  9800] loss: 0.396\n",
      "[6, 10000] loss: 0.418\n",
      "[7,   200] loss: 0.336\n",
      "[7,   400] loss: 0.436\n",
      "[7,   600] loss: 0.379\n",
      "[7,   800] loss: 0.439\n",
      "[7,  1000] loss: 0.392\n",
      "[7,  1200] loss: 0.355\n",
      "[7,  1400] loss: 0.382\n",
      "[7,  1600] loss: 0.368\n",
      "[7,  1800] loss: 0.355\n",
      "[7,  2000] loss: 0.358\n",
      "[7,  2200] loss: 0.342\n",
      "[7,  2400] loss: 0.363\n",
      "[7,  2600] loss: 0.342\n",
      "[7,  2800] loss: 0.426\n",
      "[7,  3000] loss: 0.327\n",
      "[7,  3200] loss: 0.355\n",
      "[7,  3400] loss: 0.364\n",
      "[7,  3600] loss: 0.326\n",
      "[7,  3800] loss: 0.362\n",
      "[7,  4000] loss: 0.342\n",
      "[7,  4200] loss: 0.380\n",
      "[7,  4400] loss: 0.401\n",
      "[7,  4600] loss: 0.393\n",
      "[7,  4800] loss: 0.393\n",
      "[7,  5000] loss: 0.382\n",
      "[7,  5200] loss: 0.382\n",
      "[7,  5400] loss: 0.417\n",
      "[7,  5600] loss: 0.395\n",
      "[7,  5800] loss: 0.392\n",
      "[7,  6000] loss: 0.346\n",
      "[7,  6200] loss: 0.342\n",
      "[7,  6400] loss: 0.382\n",
      "[7,  6600] loss: 0.370\n",
      "[7,  6800] loss: 0.395\n",
      "[7,  7000] loss: 0.382\n",
      "[7,  7200] loss: 0.336\n",
      "[7,  7400] loss: 0.376\n",
      "[7,  7600] loss: 0.363\n",
      "[7,  7800] loss: 0.372\n",
      "[7,  8000] loss: 0.374\n",
      "[7,  8200] loss: 0.349\n",
      "[7,  8400] loss: 0.351\n",
      "[7,  8600] loss: 0.351\n",
      "[7,  8800] loss: 0.370\n",
      "[7,  9000] loss: 0.374\n",
      "[7,  9200] loss: 0.372\n",
      "[7,  9400] loss: 0.393\n",
      "[7,  9600] loss: 0.381\n",
      "[7,  9800] loss: 0.393\n",
      "[7, 10000] loss: 0.399\n",
      "[8,   200] loss: 0.325\n",
      "[8,   400] loss: 0.343\n",
      "[8,   600] loss: 0.343\n",
      "[8,   800] loss: 0.350\n",
      "[8,  1000] loss: 0.330\n",
      "[8,  1200] loss: 0.353\n",
      "[8,  1400] loss: 0.365\n",
      "[8,  1600] loss: 0.386\n",
      "[8,  1800] loss: 0.350\n",
      "[8,  2000] loss: 0.342\n",
      "[8,  2200] loss: 0.327\n",
      "[8,  2400] loss: 0.406\n",
      "[8,  2600] loss: 0.319\n",
      "[8,  2800] loss: 0.384\n",
      "[8,  3000] loss: 0.373\n",
      "[8,  3200] loss: 0.365\n",
      "[8,  3400] loss: 0.394\n",
      "[8,  3600] loss: 0.316\n",
      "[8,  3800] loss: 0.354\n",
      "[8,  4000] loss: 0.352\n",
      "[8,  4200] loss: 0.349\n",
      "[8,  4400] loss: 0.364\n",
      "[8,  4600] loss: 0.347\n",
      "[8,  4800] loss: 0.378\n",
      "[8,  5000] loss: 0.389\n",
      "[8,  5200] loss: 0.360\n",
      "[8,  5400] loss: 0.388\n",
      "[8,  5600] loss: 0.382\n",
      "[8,  5800] loss: 0.362\n",
      "[8,  6000] loss: 0.333\n",
      "[8,  6200] loss: 0.353\n",
      "[8,  6400] loss: 0.386\n",
      "[8,  6600] loss: 0.368\n",
      "[8,  6800] loss: 0.372\n",
      "[8,  7000] loss: 0.357\n",
      "[8,  7200] loss: 0.372\n",
      "[8,  7400] loss: 0.376\n",
      "[8,  7600] loss: 0.309\n",
      "[8,  7800] loss: 0.417\n",
      "[8,  8000] loss: 0.387\n",
      "[8,  8200] loss: 0.352\n",
      "[8,  8400] loss: 0.395\n",
      "[8,  8600] loss: 0.360\n",
      "[8,  8800] loss: 0.343\n",
      "[8,  9000] loss: 0.374\n",
      "[8,  9200] loss: 0.362\n",
      "[8,  9400] loss: 0.382\n",
      "[8,  9600] loss: 0.347\n",
      "[8,  9800] loss: 0.332\n",
      "[8, 10000] loss: 0.327\n",
      "[9,   200] loss: 0.315\n",
      "[9,   400] loss: 0.332\n",
      "[9,   600] loss: 0.306\n",
      "[9,   800] loss: 0.346\n",
      "[9,  1000] loss: 0.348\n",
      "[9,  1200] loss: 0.348\n",
      "[9,  1400] loss: 0.332\n",
      "[9,  1600] loss: 0.342\n",
      "[9,  1800] loss: 0.337\n",
      "[9,  2000] loss: 0.348\n",
      "[9,  2200] loss: 0.345\n",
      "[9,  2400] loss: 0.354\n",
      "[9,  2600] loss: 0.301\n",
      "[9,  2800] loss: 0.405\n",
      "[9,  3000] loss: 0.375\n",
      "[9,  3200] loss: 0.330\n",
      "[9,  3400] loss: 0.333\n",
      "[9,  3600] loss: 0.400\n",
      "[9,  3800] loss: 0.372\n",
      "[9,  4000] loss: 0.396\n",
      "[9,  4200] loss: 0.326\n",
      "[9,  4400] loss: 0.348\n",
      "[9,  4600] loss: 0.307\n",
      "[9,  4800] loss: 0.338\n",
      "[9,  5000] loss: 0.359\n",
      "[9,  5200] loss: 0.358\n",
      "[9,  5400] loss: 0.386\n",
      "[9,  5600] loss: 0.356\n",
      "[9,  5800] loss: 0.342\n",
      "[9,  6000] loss: 0.391\n",
      "[9,  6200] loss: 0.321\n",
      "[9,  6400] loss: 0.376\n",
      "[9,  6600] loss: 0.359\n",
      "[9,  6800] loss: 0.340\n",
      "[9,  7000] loss: 0.330\n",
      "[9,  7200] loss: 0.379\n",
      "[9,  7400] loss: 0.385\n",
      "[9,  7600] loss: 0.336\n",
      "[9,  7800] loss: 0.376\n",
      "[9,  8000] loss: 0.399\n",
      "[9,  8200] loss: 0.297\n",
      "[9,  8400] loss: 0.359\n",
      "[9,  8600] loss: 0.298\n",
      "[9,  8800] loss: 0.338\n",
      "[9,  9000] loss: 0.371\n",
      "[9,  9200] loss: 0.372\n",
      "[9,  9400] loss: 0.338\n",
      "[9,  9600] loss: 0.371\n",
      "[9,  9800] loss: 0.357\n",
      "[9, 10000] loss: 0.381\n",
      "[10,   200] loss: 0.345\n",
      "[10,   400] loss: 0.343\n",
      "[10,   600] loss: 0.392\n",
      "[10,   800] loss: 0.317\n",
      "[10,  1000] loss: 0.305\n",
      "[10,  1200] loss: 0.300\n",
      "[10,  1400] loss: 0.327\n",
      "[10,  1600] loss: 0.393\n",
      "[10,  1800] loss: 0.306\n",
      "[10,  2000] loss: 0.334\n",
      "[10,  2200] loss: 0.309\n",
      "[10,  2400] loss: 0.422\n",
      "[10,  2600] loss: 0.336\n",
      "[10,  2800] loss: 0.365\n",
      "[10,  3000] loss: 0.308\n",
      "[10,  3200] loss: 0.367\n",
      "[10,  3400] loss: 0.342\n",
      "[10,  3600] loss: 0.394\n",
      "[10,  3800] loss: 0.351\n",
      "[10,  4000] loss: 0.352\n",
      "[10,  4200] loss: 0.299\n",
      "[10,  4400] loss: 0.367\n",
      "[10,  4600] loss: 0.369\n",
      "[10,  4800] loss: 0.350\n",
      "[10,  5000] loss: 0.299\n",
      "[10,  5200] loss: 0.335\n",
      "[10,  5400] loss: 0.346\n",
      "[10,  5600] loss: 0.386\n",
      "[10,  5800] loss: 0.330\n",
      "[10,  6000] loss: 0.319\n",
      "[10,  6200] loss: 0.354\n",
      "[10,  6400] loss: 0.349\n",
      "[10,  6600] loss: 0.331\n",
      "[10,  6800] loss: 0.386\n",
      "[10,  7000] loss: 0.294\n",
      "[10,  7200] loss: 0.328\n",
      "[10,  7400] loss: 0.323\n",
      "[10,  7600] loss: 0.339\n",
      "[10,  7800] loss: 0.327\n",
      "[10,  8000] loss: 0.355\n",
      "[10,  8200] loss: 0.402\n",
      "[10,  8400] loss: 0.339\n",
      "[10,  8600] loss: 0.342\n",
      "[10,  8800] loss: 0.359\n",
      "[10,  9000] loss: 0.344\n",
      "[10,  9200] loss: 0.355\n",
      "[10,  9400] loss: 0.374\n",
      "[10,  9600] loss: 0.312\n",
      "[10,  9800] loss: 0.294\n",
      "[10, 10000] loss: 0.343\n",
      "Finished Additional Training\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "additional_epochs = 5  # Number of additional epochs to train\n",
    "\n",
    "for epoch in range(5, 5 + additional_epochs):  # Continue from epoch 10 to 30\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 200 == 199:\n",
    "            print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 200))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Additional Training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 84 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6,   200] loss: 0.312\n",
      "[6,   400] loss: 0.295\n",
      "[6,   600] loss: 0.320\n",
      "[6,   800] loss: 0.351\n",
      "[6,  1000] loss: 0.343\n",
      "[6,  1200] loss: 0.316\n",
      "[6,  1400] loss: 0.302\n",
      "[6,  1600] loss: 0.403\n",
      "[6,  1800] loss: 0.299\n",
      "[6,  2000] loss: 0.334\n",
      "[6,  2200] loss: 0.314\n",
      "[6,  2400] loss: 0.320\n",
      "[6,  2600] loss: 0.320\n",
      "[6,  2800] loss: 0.313\n",
      "[6,  3000] loss: 0.328\n",
      "[6,  3200] loss: 0.327\n",
      "[6,  3400] loss: 0.305\n",
      "[6,  3600] loss: 0.309\n",
      "[6,  3800] loss: 0.372\n",
      "[6,  4000] loss: 0.302\n",
      "[6,  4200] loss: 0.348\n",
      "[6,  4400] loss: 0.331\n",
      "[6,  4600] loss: 0.403\n",
      "[6,  4800] loss: 0.357\n",
      "[6,  5000] loss: 0.335\n",
      "[6,  5200] loss: 0.336\n",
      "[6,  5400] loss: 0.334\n",
      "[6,  5600] loss: 0.323\n",
      "[6,  5800] loss: 0.347\n",
      "[6,  6000] loss: 0.340\n",
      "[6,  6200] loss: 0.337\n",
      "[6,  6400] loss: 0.350\n",
      "[6,  6600] loss: 0.363\n",
      "[6,  6800] loss: 0.342\n",
      "[6,  7000] loss: 0.327\n",
      "[6,  7200] loss: 0.315\n",
      "[6,  7400] loss: 0.306\n",
      "[6,  7600] loss: 0.308\n",
      "[6,  7800] loss: 0.356\n",
      "[6,  8000] loss: 0.295\n",
      "[6,  8200] loss: 0.289\n",
      "[6,  8400] loss: 0.351\n",
      "[6,  8600] loss: 0.307\n",
      "[6,  8800] loss: 0.332\n",
      "[6,  9000] loss: 0.322\n",
      "[6,  9200] loss: 0.372\n",
      "[6,  9400] loss: 0.317\n",
      "[6,  9600] loss: 0.380\n",
      "[6,  9800] loss: 0.313\n",
      "[6, 10000] loss: 0.343\n",
      "[7,   200] loss: 0.326\n",
      "[7,   400] loss: 0.307\n",
      "[7,   600] loss: 0.319\n",
      "[7,   800] loss: 0.356\n",
      "[7,  1000] loss: 0.288\n",
      "[7,  1200] loss: 0.277\n",
      "[7,  1400] loss: 0.355\n",
      "[7,  1600] loss: 0.275\n",
      "[7,  1800] loss: 0.288\n",
      "[7,  2000] loss: 0.289\n",
      "[7,  2200] loss: 0.382\n",
      "[7,  2400] loss: 0.321\n",
      "[7,  2600] loss: 0.297\n",
      "[7,  2800] loss: 0.313\n",
      "[7,  3000] loss: 0.316\n",
      "[7,  3200] loss: 0.328\n",
      "[7,  3400] loss: 0.360\n",
      "[7,  3600] loss: 0.336\n",
      "[7,  3800] loss: 0.319\n",
      "[7,  4000] loss: 0.328\n",
      "[7,  4200] loss: 0.322\n",
      "[7,  4400] loss: 0.340\n",
      "[7,  4600] loss: 0.317\n",
      "[7,  4800] loss: 0.323\n",
      "[7,  5000] loss: 0.307\n",
      "[7,  5200] loss: 0.290\n",
      "[7,  5400] loss: 0.319\n",
      "[7,  5600] loss: 0.341\n",
      "[7,  5800] loss: 0.364\n",
      "[7,  6000] loss: 0.318\n",
      "[7,  6200] loss: 0.344\n",
      "[7,  6400] loss: 0.298\n",
      "[7,  6600] loss: 0.296\n",
      "[7,  6800] loss: 0.315\n",
      "[7,  7000] loss: 0.321\n",
      "[7,  7200] loss: 0.336\n",
      "[7,  7400] loss: 0.333\n",
      "[7,  7600] loss: 0.344\n",
      "[7,  7800] loss: 0.318\n",
      "[7,  8000] loss: 0.331\n",
      "[7,  8200] loss: 0.294\n",
      "[7,  8400] loss: 0.318\n",
      "[7,  8600] loss: 0.279\n",
      "[7,  8800] loss: 0.311\n",
      "[7,  9000] loss: 0.251\n",
      "[7,  9200] loss: 0.353\n",
      "[7,  9400] loss: 0.307\n",
      "[7,  9600] loss: 0.334\n",
      "[7,  9800] loss: 0.290\n",
      "[7, 10000] loss: 0.359\n",
      "[8,   200] loss: 0.295\n",
      "[8,   400] loss: 0.322\n",
      "[8,   600] loss: 0.332\n",
      "[8,   800] loss: 0.282\n",
      "[8,  1000] loss: 0.309\n",
      "[8,  1200] loss: 0.335\n",
      "[8,  1400] loss: 0.305\n",
      "[8,  1600] loss: 0.290\n",
      "[8,  1800] loss: 0.313\n",
      "[8,  2000] loss: 0.336\n",
      "[8,  2200] loss: 0.345\n",
      "[8,  2400] loss: 0.284\n",
      "[8,  2600] loss: 0.347\n",
      "[8,  2800] loss: 0.329\n",
      "[8,  3000] loss: 0.294\n",
      "[8,  3200] loss: 0.322\n",
      "[8,  3400] loss: 0.287\n",
      "[8,  3600] loss: 0.345\n",
      "[8,  3800] loss: 0.308\n",
      "[8,  4000] loss: 0.383\n",
      "[8,  4200] loss: 0.295\n",
      "[8,  4400] loss: 0.354\n",
      "[8,  4600] loss: 0.322\n",
      "[8,  4800] loss: 0.280\n",
      "[8,  5000] loss: 0.294\n",
      "[8,  5200] loss: 0.342\n",
      "[8,  5400] loss: 0.312\n",
      "[8,  5600] loss: 0.317\n",
      "[8,  5800] loss: 0.295\n",
      "[8,  6000] loss: 0.335\n",
      "[8,  6200] loss: 0.355\n",
      "[8,  6400] loss: 0.339\n",
      "[8,  6600] loss: 0.308\n",
      "[8,  6800] loss: 0.294\n",
      "[8,  7000] loss: 0.360\n",
      "[8,  7200] loss: 0.258\n",
      "[8,  7400] loss: 0.328\n",
      "[8,  7600] loss: 0.331\n",
      "[8,  7800] loss: 0.322\n",
      "[8,  8000] loss: 0.321\n",
      "[8,  8200] loss: 0.331\n",
      "[8,  8400] loss: 0.305\n",
      "[8,  8600] loss: 0.356\n",
      "[8,  8800] loss: 0.395\n",
      "[8,  9000] loss: 0.331\n",
      "[8,  9200] loss: 0.319\n",
      "[8,  9400] loss: 0.314\n",
      "[8,  9600] loss: 0.304\n",
      "[8,  9800] loss: 0.304\n",
      "[8, 10000] loss: 0.325\n",
      "[9,   200] loss: 0.333\n",
      "[9,   400] loss: 0.319\n",
      "[9,   600] loss: 0.310\n",
      "[9,   800] loss: 0.301\n",
      "[9,  1000] loss: 0.322\n",
      "[9,  1200] loss: 0.338\n",
      "[9,  1400] loss: 0.318\n",
      "[9,  1600] loss: 0.290\n",
      "[9,  1800] loss: 0.325\n",
      "[9,  2000] loss: 0.344\n",
      "[9,  2200] loss: 0.304\n",
      "[9,  2400] loss: 0.262\n",
      "[9,  2600] loss: 0.291\n",
      "[9,  2800] loss: 0.266\n",
      "[9,  3000] loss: 0.323\n",
      "[9,  3200] loss: 0.325\n",
      "[9,  3400] loss: 0.301\n",
      "[9,  3600] loss: 0.339\n",
      "[9,  3800] loss: 0.310\n",
      "[9,  4000] loss: 0.300\n",
      "[9,  4200] loss: 0.281\n",
      "[9,  4400] loss: 0.330\n",
      "[9,  4600] loss: 0.304\n",
      "[9,  4800] loss: 0.286\n",
      "[9,  5000] loss: 0.301\n",
      "[9,  5200] loss: 0.239\n",
      "[9,  5400] loss: 0.292\n",
      "[9,  5600] loss: 0.302\n",
      "[9,  5800] loss: 0.316\n",
      "[9,  6000] loss: 0.266\n",
      "[9,  6200] loss: 0.297\n",
      "[9,  6400] loss: 0.306\n",
      "[9,  6600] loss: 0.244\n",
      "[9,  6800] loss: 0.292\n",
      "[9,  7000] loss: 0.330\n",
      "[9,  7200] loss: 0.332\n",
      "[9,  7400] loss: 0.326\n",
      "[9,  7600] loss: 0.277\n",
      "[9,  7800] loss: 0.314\n",
      "[9,  8000] loss: 0.338\n",
      "[9,  8200] loss: 0.319\n",
      "[9,  8400] loss: 0.257\n",
      "[9,  8600] loss: 0.335\n",
      "[9,  8800] loss: 0.302\n",
      "[9,  9000] loss: 0.317\n",
      "[9,  9200] loss: 0.306\n",
      "[9,  9400] loss: 0.265\n",
      "[9,  9600] loss: 0.337\n",
      "[9,  9800] loss: 0.306\n",
      "[9, 10000] loss: 0.287\n",
      "[10,   200] loss: 0.279\n",
      "[10,   400] loss: 0.301\n",
      "[10,   600] loss: 0.294\n",
      "[10,   800] loss: 0.256\n",
      "[10,  1000] loss: 0.314\n",
      "[10,  1200] loss: 0.283\n",
      "[10,  1400] loss: 0.264\n",
      "[10,  1600] loss: 0.299\n",
      "[10,  1800] loss: 0.366\n",
      "[10,  2000] loss: 0.241\n",
      "[10,  2200] loss: 0.290\n",
      "[10,  2400] loss: 0.300\n",
      "[10,  2600] loss: 0.295\n",
      "[10,  2800] loss: 0.253\n",
      "[10,  3000] loss: 0.322\n",
      "[10,  3200] loss: 0.361\n",
      "[10,  3400] loss: 0.249\n",
      "[10,  3600] loss: 0.300\n",
      "[10,  3800] loss: 0.274\n",
      "[10,  4000] loss: 0.315\n",
      "[10,  4200] loss: 0.310\n",
      "[10,  4400] loss: 0.276\n",
      "[10,  4600] loss: 0.297\n",
      "[10,  4800] loss: 0.269\n",
      "[10,  5000] loss: 0.295\n",
      "[10,  5200] loss: 0.279\n",
      "[10,  5400] loss: 0.309\n",
      "[10,  5600] loss: 0.291\n",
      "[10,  5800] loss: 0.301\n",
      "[10,  6000] loss: 0.377\n",
      "[10,  6200] loss: 0.353\n",
      "[10,  6400] loss: 0.291\n",
      "[10,  6600] loss: 0.261\n",
      "[10,  6800] loss: 0.321\n",
      "[10,  7000] loss: 0.267\n",
      "[10,  7200] loss: 0.279\n",
      "[10,  7400] loss: 0.286\n",
      "[10,  7600] loss: 0.274\n",
      "[10,  7800] loss: 0.297\n",
      "[10,  8000] loss: 0.320\n",
      "[10,  8200] loss: 0.292\n",
      "[10,  8400] loss: 0.290\n",
      "[10,  8600] loss: 0.318\n",
      "[10,  8800] loss: 0.307\n",
      "[10,  9000] loss: 0.337\n",
      "[10,  9200] loss: 0.302\n",
      "[10,  9400] loss: 0.296\n",
      "[10,  9600] loss: 0.324\n",
      "[10,  9800] loss: 0.297\n",
      "[10, 10000] loss: 0.298\n",
      "Finished Additional Training\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "additional_epochs = 5  # Number of additional epochs to train\n",
    "\n",
    "for epoch in range(5, 5 + additional_epochs):  # Continue from epoch 10 to 30\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 200 == 199:\n",
    "            print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 200))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Additional Training')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 84 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
